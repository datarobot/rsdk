# Copyright 2021-2022 DataRobot, Inc. and its affiliates.
#
# All rights reserved.
#
# DataRobot, Inc.
#
# This is proprietary source code of DataRobot, Inc. and its
# affiliates.

# Public API
#
# DataRobot's Public facing API
#
# The version of the OpenAPI document: 2.29.0
# Contact: api-maintainer@datarobot.com
# Generated by: https://openapi-generator.tech

#' @docType class
#' @title BatchPredictionJobSpecResponse
#'
#' @description BatchPredictionJobSpecResponse Class
#'
#' @format An \code{R6Class} generator object
#'
#' @field abortOnError  character Should this job abort if too many errors are encountered
#'
#' @field chunkSize  \link{OneOfstringinteger} [optional] Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
#'
#' @field columnNamesRemapping  \link{OneOfobjectarray} [optional] Remap (rename or remove columns from) the output from this job
#'
#' @field csvSettings  \link{BatchPredictionJobCSVSettings}
#'
#' @field deploymentId  character [optional] ID of deployment which is used in job for processing predictions dataset
#'
#' @field disableRowLevelErrorHandling  character Skip row by row error handling
#'
#' @field explanationAlgorithm  character [optional] Which algorithm will be used to calculate prediction explanations
#'
#' @field explanationClassNames  list( character ) [optional] List of class names that will be explained for each row for multiclass. Mutually exclusive with explanationNumTopClasses. If neither specified - we assume explanationNumTopClasses&#x3D;1
#'
#' @field explanationNumTopClasses  integer [optional] Number of top predicted classes for each row that will be explained for multiclass. Mutually exclusive with explanationClassNames. If neither specified - we assume explanationNumTopClasses&#x3D;1
#'
#' @field includePredictionStatus  character Include prediction status column in the output
#'
#' @field includeProbabilities  character Include probabilities for all classes
#'
#' @field includeProbabilitiesClasses  list( character ) Include only probabilities for these specific class names.
#'
#' @field intakeSettings  \link{OneOfDataStageDataStreamerDSSDataStreamerCatalogDataStreamerFileSystemDataStreamerHTTPDataStreamerJDBCDataStreamerLocalFileDataStreamerAzureDataStreamerGCPDataStreamerBigQueryDataStreamerS3DataStreamerSnowflakeDataStreamerSynapseDataStreamer} The response option configured for this job
#'
#' @field maxExplanations  integer Number of explanations requested. Will be ordered by strength.
#'
#' @field modelId  character [optional] ID of leaderboard model which is used in job for processing predictions dataset
#'
#' @field modelPackageId  character [optional] ID of model package from registry is used in job for processing predictions dataset
#'
#' @field numConcurrent  integer [optional] Number of simultaneous requests to run against the prediction instance
#'
#' @field outputSettings  \link{OneOfFileSystemOutputAdaptorHttpOutputAdaptorJdbcOutputAdaptorLocalFileOutputAdaptorTableauOutputAdaptorAzureOutputAdaptorGCPOutputAdaptorBigQueryOutputAdaptorS3OutputAdaptorSnowflakeOutputAdaptorSynapseOutputAdaptor} The response option configured for this job
#'
#' @field passthroughColumns  list( character ) [optional] Pass through columns from the original dataset
#'
#' @field passthroughColumnsSet  character [optional] Pass through all columns from the original dataset
#'
#' @field pinnedModelId  character [optional] Specify a model ID used for scoring
#'
#' @field predictionInstance  \link{BatchPredictionJobPredictionInstance} [optional]
#'
#' @field predictionWarningEnabled  character [optional] Enable prediction warnings.
#'
#' @field skipDriftTracking  character Skip drift tracking for this job.
#'
#' @field thresholdHigh  numeric [optional] Compute explanations for predictions above this threshold
#'
#' @field thresholdLow  numeric [optional] Compute explanations for predictions below this threshold
#'
#' @field timeseriesSettings  \link{OneOfBatchPredictionJobTimeSeriesSettingsForecastBatchPredictionJobTimeSeriesSettingsHistorical} [optional] Time Series settings included of this job is a Time Series job.
#'
#' @importFrom R6 R6Class
#' @importFrom jsonlite fromJSON toJSON
#' @export
BatchPredictionJobSpecResponse <- R6::R6Class(
  "BatchPredictionJobSpecResponse",
  lock_objects = FALSE,
  private = list(
    # @description The properties of this object that are required to be set.
    # @description A helper function to handle assist with type validation. This function will validate class parameters with definite
    # types assigned to them, as well as handling validation of parameters with anyOf and oneOf types listed. These types
    # can themselves be other R6 objects.
    validateProps = function(`abortOnError` = NULL, `chunkSize` = NULL, `columnNamesRemapping` = NULL, `csvSettings` = NULL, `deploymentId` = NULL, `disableRowLevelErrorHandling` = NULL, `explanationAlgorithm` = NULL, `explanationClassNames` = NULL, `explanationNumTopClasses` = NULL, `includePredictionStatus` = NULL, `includeProbabilities` = NULL, `includeProbabilitiesClasses` = NULL, `intakeSettings` = NULL, `maxExplanations` = NULL, `modelId` = NULL, `modelPackageId` = NULL, `numConcurrent` = NULL, `outputSettings` = NULL, `passthroughColumns` = NULL, `passthroughColumnsSet` = NULL, `pinnedModelId` = NULL, `predictionInstance` = NULL, `predictionWarningEnabled` = NULL, `skipDriftTracking` = NULL, `thresholdHigh` = NULL, `thresholdLow` = NULL, `timeseriesSettings` = NULL) {
      if (!is.null(`abortOnError`)) {
        stopifnot(is.logical(`abortOnError`), length(`abortOnError`) == 1)
      }
      if (!is.null(`csvSettings`)) {
        stopifnot(R6::is.R6(`csvSettings`))
      }
      if (!is.null(`disableRowLevelErrorHandling`)) {
        stopifnot(is.logical(`disableRowLevelErrorHandling`), length(`disableRowLevelErrorHandling`) == 1)
      }
      if (!is.null(`includePredictionStatus`)) {
        stopifnot(is.logical(`includePredictionStatus`), length(`includePredictionStatus`) == 1)
      }
      if (!is.null(`includeProbabilities`)) {
        stopifnot(is.logical(`includeProbabilities`), length(`includeProbabilities`) == 1)
      }
      if (!is.null(`includeProbabilitiesClasses`)) {
        stopifnot(is.vector(`includeProbabilitiesClasses`), sapply(`includeProbabilitiesClasses`, is.character))
      }
      if (!is.null(`intakeSettings`)) {
        .setComplexProperty(typeList = list(DataStageDataStreamer, DSSDataStreamer, CatalogDataStreamer, FileSystemDataStreamer, HTTPDataStreamer, JDBCDataStreamer, LocalFileDataStreamer, AzureDataStreamer, GCPDataStreamer, BigQueryDataStreamer, S3DataStreamer, SnowflakeDataStreamer, SynapseDataStreamer), propertyData = intakeSettings)
      }
      if (!is.null(`maxExplanations`)) {
        stopifnot(is.numeric(`maxExplanations`), length(`maxExplanations`) == 1)
      }
      if (!is.null(`outputSettings`)) {
        .setComplexProperty(typeList = list(FileSystemOutputAdaptor, HttpOutputAdaptor, JdbcOutputAdaptor, LocalFileOutputAdaptor, TableauOutputAdaptor, AzureOutputAdaptor, GCPOutputAdaptor, BigQueryOutputAdaptor, S3OutputAdaptor, SnowflakeOutputAdaptor, SynapseOutputAdaptor), propertyData = outputSettings)
      }
      if (!is.null(`skipDriftTracking`)) {
        stopifnot(is.logical(`skipDriftTracking`), length(`skipDriftTracking`) == 1)
      }
      if (!is.null(`chunkSize`)) {
        .setPrimitiveProperty(typeList = list("character", "numeric"), propertyData = chunkSize)
      }
      if (!is.null(`columnNamesRemapping`)) {
        .setPrimitiveProperty(typeList = list("character", "array"), propertyData = columnNamesRemapping)
      }
      if (!is.null(`deploymentId`)) {
        stopifnot(is.character(`deploymentId`), length(`deploymentId`) == 1)
      }
      if (!is.null(`explanationAlgorithm`)) {
        stopifnot(is.character(`explanationAlgorithm`), length(`explanationAlgorithm`) == 1)
      }
      if (!is.null(`explanationClassNames`) && length(`explanationClassNames`) > 0) {
        stopifnot(is.vector(`explanationClassNames`), sapply(`explanationClassNames`, is.character))
      }
      if (!is.null(`explanationNumTopClasses`)) {
        stopifnot(is.numeric(`explanationNumTopClasses`), length(`explanationNumTopClasses`) == 1)
      }
      if (!is.null(`modelId`)) {
        stopifnot(is.character(`modelId`), length(`modelId`) == 1)
      }
      if (!is.null(`modelPackageId`)) {
        stopifnot(is.character(`modelPackageId`), length(`modelPackageId`) == 1)
      }
      if (!is.null(`numConcurrent`)) {
        stopifnot(is.numeric(`numConcurrent`), length(`numConcurrent`) == 1)
      }
      if (!is.null(`passthroughColumns`) && length(`passthroughColumns`) > 0) {
        stopifnot(is.vector(`passthroughColumns`), sapply(`passthroughColumns`, is.character))
      }
      if (!is.null(`passthroughColumnsSet`)) {
        stopifnot(is.character(`passthroughColumnsSet`), length(`passthroughColumnsSet`) == 1)
      }
      if (!is.null(`pinnedModelId`)) {
        stopifnot(is.character(`pinnedModelId`), length(`pinnedModelId`) == 1)
      }
      if (!is.null(`predictionInstance`)) {
        stopifnot(R6::is.R6(`predictionInstance`))
      }
      if (!is.null(`predictionWarningEnabled`)) {
        stopifnot(is.logical(`predictionWarningEnabled`), length(`predictionWarningEnabled`) == 1)
      }
      if (!is.null(`thresholdHigh`)) {
        stopifnot(is.numeric(`thresholdHigh`), length(`thresholdHigh`) == 1)
      }
      if (!is.null(`thresholdLow`)) {
        stopifnot(is.numeric(`thresholdLow`), length(`thresholdLow`) == 1)
      }
      if (!is.null(`timeseriesSettings`)) {
        .setComplexProperty(typeList = list(BatchPredictionJobTimeSeriesSettingsForecast, BatchPredictionJobTimeSeriesSettingsHistorical), propertyData = timeseriesSettings)
      }
    }
  ),
  public = list(
    `abortOnError` = NULL,
    `chunkSize` = NULL,
    `columnNamesRemapping` = NULL,
    `csvSettings` = NULL,
    `deploymentId` = NULL,
    `disableRowLevelErrorHandling` = NULL,
    `explanationAlgorithm` = NULL,
    `explanationClassNames` = NULL,
    `explanationNumTopClasses` = NULL,
    `includePredictionStatus` = NULL,
    `includeProbabilities` = NULL,
    `includeProbabilitiesClasses` = NULL,
    `intakeSettings` = NULL,
    `maxExplanations` = NULL,
    `modelId` = NULL,
    `modelPackageId` = NULL,
    `numConcurrent` = NULL,
    `outputSettings` = NULL,
    `passthroughColumns` = NULL,
    `passthroughColumnsSet` = NULL,
    `pinnedModelId` = NULL,
    `predictionInstance` = NULL,
    `predictionWarningEnabled` = NULL,
    `skipDriftTracking` = NULL,
    `thresholdHigh` = NULL,
    `thresholdLow` = NULL,
    `timeseriesSettings` = NULL,
    #' @description A function used to initialize an instance of this class.
    #' @param abortOnError Should this job abort if too many errors are encountered
    #' @param chunkSize Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
    #' @param columnNamesRemapping Remap (rename or remove columns from) the output from this job
    #' @param csvSettings
    #' @param deploymentId ID of deployment which is used in job for processing predictions dataset
    #' @param disableRowLevelErrorHandling Skip row by row error handling
    #' @param explanationAlgorithm Which algorithm will be used to calculate prediction explanations
    #' @param explanationClassNames List of class names that will be explained for each row for multiclass. Mutually exclusive with explanationNumTopClasses. If neither specified - we assume explanationNumTopClasses&#x3D;1
    #' @param explanationNumTopClasses Number of top predicted classes for each row that will be explained for multiclass. Mutually exclusive with explanationClassNames. If neither specified - we assume explanationNumTopClasses&#x3D;1
    #' @param includePredictionStatus Include prediction status column in the output
    #' @param includeProbabilities Include probabilities for all classes
    #' @param includeProbabilitiesClasses Include only probabilities for these specific class names.
    #' @param intakeSettings The response option configured for this job
    #' @param maxExplanations Number of explanations requested. Will be ordered by strength.
    #' @param modelId ID of leaderboard model which is used in job for processing predictions dataset
    #' @param modelPackageId ID of model package from registry is used in job for processing predictions dataset
    #' @param numConcurrent Number of simultaneous requests to run against the prediction instance
    #' @param outputSettings The response option configured for this job
    #' @param passthroughColumns Pass through columns from the original dataset
    #' @param passthroughColumnsSet Pass through all columns from the original dataset
    #' @param pinnedModelId Specify a model ID used for scoring
    #' @param predictionInstance
    #' @param predictionWarningEnabled Enable prediction warnings.
    #' @param skipDriftTracking Skip drift tracking for this job.
    #' @param thresholdHigh Compute explanations for predictions above this threshold
    #' @param thresholdLow Compute explanations for predictions below this threshold
    #' @param timeseriesSettings Time Series settings included of this job is a Time Series job.
    #' @param validateParams An optional param for auto validating this object's parameters before initialization. Default FALSE.
    #' @param ... Any additional keyword arguments to be passed into this object for initialization.
    initialize = function(`abortOnError` = NULL, `csvSettings` = NULL, `disableRowLevelErrorHandling` = NULL, `includePredictionStatus` = NULL, `includeProbabilities` = NULL, `includeProbabilitiesClasses` = NULL, `intakeSettings` = NULL, `maxExplanations` = NULL, `outputSettings` = NULL, `skipDriftTracking` = NULL, `chunkSize` = NULL, `columnNamesRemapping` = NULL, `deploymentId` = NULL, `explanationAlgorithm` = NULL, `explanationClassNames` = NULL, `explanationNumTopClasses` = NULL, `modelId` = NULL, `modelPackageId` = NULL, `numConcurrent` = NULL, `passthroughColumns` = NULL, `passthroughColumnsSet` = NULL, `pinnedModelId` = NULL, `predictionInstance` = NULL, `predictionWarningEnabled` = NULL, `thresholdHigh` = NULL, `thresholdLow` = NULL, `timeseriesSettings` = NULL, validateParams = FALSE, ...) {
      local.optional.var <- list(...)
      if (validateParams) {
        lapply(list(`abortOnError`, `csvSettings`, `disableRowLevelErrorHandling`, `includePredictionStatus`, `includeProbabilities`, `includeProbabilitiesClasses`, `intakeSettings`, `maxExplanations`, `outputSettings`, `skipDriftTracking`), function(param) {
          stopifnot("Required param not set." = !is.null(param))
        })
        private$validateProps(abortOnError, chunkSize, columnNamesRemapping, csvSettings, deploymentId, disableRowLevelErrorHandling, explanationAlgorithm, explanationClassNames, explanationNumTopClasses, includePredictionStatus, includeProbabilities, includeProbabilitiesClasses, intakeSettings, maxExplanations, modelId, modelPackageId, numConcurrent, outputSettings, passthroughColumns, passthroughColumnsSet, pinnedModelId, predictionInstance, predictionWarningEnabled, skipDriftTracking, thresholdHigh, thresholdLow, timeseriesSettings)
      }
      self$`abortOnError` <- `abortOnError`
      self$`chunkSize` <- .setPrimitiveProperty(typeList = list("character", "numeric"), propertyData = chunkSize)
      self$`columnNamesRemapping` <- .setPrimitiveProperty(typeList = list("character", "array"), propertyData = columnNamesRemapping)
      self$`csvSettings` <- `csvSettings`
      self$`deploymentId` <- `deploymentId`
      self$`disableRowLevelErrorHandling` <- `disableRowLevelErrorHandling`
      self$`explanationAlgorithm` <- `explanationAlgorithm`
      self$`explanationClassNames` <- `explanationClassNames`
      self$`explanationNumTopClasses` <- `explanationNumTopClasses`
      self$`includePredictionStatus` <- `includePredictionStatus`
      self$`includeProbabilities` <- `includeProbabilities`
      self$`includeProbabilitiesClasses` <- `includeProbabilitiesClasses`
      self$`intakeSettings` <- .setComplexProperty(typeList = list(DataStageDataStreamer, DSSDataStreamer, CatalogDataStreamer, FileSystemDataStreamer, HTTPDataStreamer, JDBCDataStreamer, LocalFileDataStreamer, AzureDataStreamer, GCPDataStreamer, BigQueryDataStreamer, S3DataStreamer, SnowflakeDataStreamer, SynapseDataStreamer), propertyData = intakeSettings)
      self$`maxExplanations` <- `maxExplanations`
      self$`modelId` <- `modelId`
      self$`modelPackageId` <- `modelPackageId`
      self$`numConcurrent` <- `numConcurrent`
      self$`outputSettings` <- .setComplexProperty(typeList = list(FileSystemOutputAdaptor, HttpOutputAdaptor, JdbcOutputAdaptor, LocalFileOutputAdaptor, TableauOutputAdaptor, AzureOutputAdaptor, GCPOutputAdaptor, BigQueryOutputAdaptor, S3OutputAdaptor, SnowflakeOutputAdaptor, SynapseOutputAdaptor), propertyData = outputSettings)
      self$`passthroughColumns` <- `passthroughColumns`
      self$`passthroughColumnsSet` <- `passthroughColumnsSet`
      self$`pinnedModelId` <- `pinnedModelId`
      self$`predictionInstance` <- `predictionInstance`
      self$`predictionWarningEnabled` <- `predictionWarningEnabled`
      self$`skipDriftTracking` <- `skipDriftTracking`
      self$`thresholdHigh` <- `thresholdHigh`
      self$`thresholdLow` <- `thresholdLow`
      self$`timeseriesSettings` <- .setComplexProperty(typeList = list(BatchPredictionJobTimeSeriesSettingsForecast, BatchPredictionJobTimeSeriesSettingsHistorical), propertyData = timeseriesSettings)
    },
    #' @description A helper function that provides public access to the private validateProps function. This allows users the ability
    #' to programmatically validate objects before sending them to DataRobot.
    #' checking this objects set properties.
    validate = function() {
      do.call(private$validateProps, list(abortOnError = self$`abortOnError`, chunkSize = self$`chunkSize`, columnNamesRemapping = self$`columnNamesRemapping`, csvSettings = self$`csvSettings`, deploymentId = self$`deploymentId`, disableRowLevelErrorHandling = self$`disableRowLevelErrorHandling`, explanationAlgorithm = self$`explanationAlgorithm`, explanationClassNames = self$`explanationClassNames`, explanationNumTopClasses = self$`explanationNumTopClasses`, includePredictionStatus = self$`includePredictionStatus`, includeProbabilities = self$`includeProbabilities`, includeProbabilitiesClasses = self$`includeProbabilitiesClasses`, intakeSettings = self$`intakeSettings`, maxExplanations = self$`maxExplanations`, modelId = self$`modelId`, modelPackageId = self$`modelPackageId`, numConcurrent = self$`numConcurrent`, outputSettings = self$`outputSettings`, passthroughColumns = self$`passthroughColumns`, passthroughColumnsSet = self$`passthroughColumnsSet`, pinnedModelId = self$`pinnedModelId`, predictionInstance = self$`predictionInstance`, predictionWarningEnabled = self$`predictionWarningEnabled`, skipDriftTracking = self$`skipDriftTracking`, thresholdHigh = self$`thresholdHigh`, thresholdLow = self$`thresholdLow`, timeseriesSettings = self$`timeseriesSettings`))
    },
    #' @description A helper function that serializes this object into a JSON encoded string.
    toJSON = function() {
      jsoncontent <- c(
        if (!is.null(self$`abortOnError`)) {
          sprintf(
            '"abortOnError":
            %s
                  ',
            tolower(self$`abortOnError`)
          )
        },
        if (!is.null(self$`chunkSize`)) {
          sprintf(
            '"chunkSize":
            %s
      ',
            self$`chunkSize`
          )
        },
        if (!is.null(self$`columnNamesRemapping`)) {
          sprintf(
            '"columnNamesRemapping":
            %s
      ',
            self$`columnNamesRemapping`
          )
        },
        if (!is.null(self$`csvSettings`)) {
          sprintf(
            '"csvSettings":
            %s
      ',
            jsonlite::toJSON(self$`csvSettings`$toJSON(), auto_unbox = TRUE, digits = NA)
          )
        },
        if (!is.null(self$`deploymentId`)) {
          sprintf(
            '"deploymentId":
            "%s"
                  ',
            self$`deploymentId`
          )
        },
        if (!is.null(self$`disableRowLevelErrorHandling`)) {
          sprintf(
            '"disableRowLevelErrorHandling":
            %s
                  ',
            tolower(self$`disableRowLevelErrorHandling`)
          )
        },
        if (!is.null(self$`explanationAlgorithm`)) {
          sprintf(
            '"explanationAlgorithm":
            "%s"
                  ',
            self$`explanationAlgorithm`
          )
        },
        if (!is.null(self$`explanationClassNames`)) {
          sprintf(
            '"explanationClassNames":
            [%s]
                  ',
            paste(unlist(lapply(self$`explanationClassNames`, function(x) paste0('"', x, '"'))), collapse = ",")
          )
        },
        if (!is.null(self$`explanationNumTopClasses`)) {
          sprintf(
            '"explanationNumTopClasses":
            %d
                  ',
            self$`explanationNumTopClasses`
          )
        },
        if (!is.null(self$`includePredictionStatus`)) {
          sprintf(
            '"includePredictionStatus":
            %s
                  ',
            tolower(self$`includePredictionStatus`)
          )
        },
        if (!is.null(self$`includeProbabilities`)) {
          sprintf(
            '"includeProbabilities":
            %s
                  ',
            tolower(self$`includeProbabilities`)
          )
        },
        if (!is.null(self$`includeProbabilitiesClasses`)) {
          sprintf(
            '"includeProbabilitiesClasses":
            [%s]
                  ',
            paste(unlist(lapply(self$`includeProbabilitiesClasses`, function(x) paste0('"', x, '"'))), collapse = ",")
          )
        },
        if (!is.null(self$`intakeSettings`)) {
          sprintf(
            '"intakeSettings":
            %s
      ',
            jsonlite::toJSON(self$`intakeSettings`$toJSON(), auto_unbox = TRUE, digits = NA)
          )
        },
        if (!is.null(self$`maxExplanations`)) {
          sprintf(
            '"maxExplanations":
            %d
                  ',
            self$`maxExplanations`
          )
        },
        if (!is.null(self$`modelId`)) {
          sprintf(
            '"modelId":
            "%s"
                  ',
            self$`modelId`
          )
        },
        if (!is.null(self$`modelPackageId`)) {
          sprintf(
            '"modelPackageId":
            "%s"
                  ',
            self$`modelPackageId`
          )
        },
        if (!is.null(self$`numConcurrent`)) {
          sprintf(
            '"numConcurrent":
            %d
                  ',
            self$`numConcurrent`
          )
        },
        if (!is.null(self$`outputSettings`)) {
          sprintf(
            '"outputSettings":
            %s
      ',
            jsonlite::toJSON(self$`outputSettings`$toJSON(), auto_unbox = TRUE, digits = NA)
          )
        },
        if (!is.null(self$`passthroughColumns`)) {
          sprintf(
            '"passthroughColumns":
            [%s]
                  ',
            paste(unlist(lapply(self$`passthroughColumns`, function(x) paste0('"', x, '"'))), collapse = ",")
          )
        },
        if (!is.null(self$`passthroughColumnsSet`)) {
          sprintf(
            '"passthroughColumnsSet":
            "%s"
                  ',
            self$`passthroughColumnsSet`
          )
        },
        if (!is.null(self$`pinnedModelId`)) {
          sprintf(
            '"pinnedModelId":
            "%s"
                  ',
            self$`pinnedModelId`
          )
        },
        if (!is.null(self$`predictionInstance`)) {
          sprintf(
            '"predictionInstance":
            %s
      ',
            jsonlite::toJSON(self$`predictionInstance`$toJSON(), auto_unbox = TRUE, digits = NA)
          )
        },
        if (!is.null(self$`predictionWarningEnabled`)) {
          sprintf(
            '"predictionWarningEnabled":
            %s
                  ',
            tolower(self$`predictionWarningEnabled`)
          )
        },
        if (!is.null(self$`skipDriftTracking`)) {
          sprintf(
            '"skipDriftTracking":
            %s
                  ',
            tolower(self$`skipDriftTracking`)
          )
        },
        if (!is.null(self$`thresholdHigh`)) {
          sprintf(
            '"thresholdHigh":
            %d
                  ',
            self$`thresholdHigh`
          )
        },
        if (!is.null(self$`thresholdLow`)) {
          sprintf(
            '"thresholdLow":
            %d
                  ',
            self$`thresholdLow`
          )
        },
        if (!is.null(self$`timeseriesSettings`)) {
          sprintf(
            '"timeseriesSettings":
            %s
      ',
            jsonlite::toJSON(self$`timeseriesSettings`$toJSON(), auto_unbox = TRUE, digits = NA)
          )
        }
      )
      jsoncontent <- paste(jsoncontent, collapse = ",")
      paste("{", jsoncontent, "}", sep = "")
    },
    #' @description A helper function that deserializes a JSON string into an instance of this class.
    #' @param BatchPredictionJobSpecResponseJson A JSON encoded string representation of a class instance.
    #' @param validateParams An optional param for auto validating this object's parameters after deserialization. Default FALSE.
    fromJSON = function(BatchPredictionJobSpecResponseJson, validateParams = FALSE) {
      BatchPredictionJobSpecResponseObject <- jsonlite::fromJSON(BatchPredictionJobSpecResponseJson)
      self$`abortOnError` <- BatchPredictionJobSpecResponseObject$`abortOnError`
      self$`chunkSize` <- .setPrimitiveProperty(typeList = list("character", "numeric"), propertyData = BatchPredictionJobSpecResponseObject$chunkSize)
      self$`columnNamesRemapping` <- .setPrimitiveProperty(typeList = list("character", "array"), propertyData = BatchPredictionJobSpecResponseObject$columnNamesRemapping)
      self$`csvSettings` <- BatchPredictionJobCSVSettings$new()$fromJSON(jsonlite::toJSON(BatchPredictionJobSpecResponseObject$csvSettings, auto_unbox = TRUE, digits = NA, null = "null"))
      self$`deploymentId` <- BatchPredictionJobSpecResponseObject$`deploymentId`
      self$`disableRowLevelErrorHandling` <- BatchPredictionJobSpecResponseObject$`disableRowLevelErrorHandling`
      self$`explanationAlgorithm` <- BatchPredictionJobSpecResponseObject$`explanationAlgorithm`
      self$`explanationClassNames` <- ApiClient$new()$deserializeObj(BatchPredictionJobSpecResponseObject$`explanationClassNames`, "array[character]", loadNamespace("datarobot.apicore"))
      self$`explanationNumTopClasses` <- BatchPredictionJobSpecResponseObject$`explanationNumTopClasses`
      self$`includePredictionStatus` <- BatchPredictionJobSpecResponseObject$`includePredictionStatus`
      self$`includeProbabilities` <- BatchPredictionJobSpecResponseObject$`includeProbabilities`
      self$`includeProbabilitiesClasses` <- ApiClient$new()$deserializeObj(BatchPredictionJobSpecResponseObject$`includeProbabilitiesClasses`, "array[character]", loadNamespace("datarobot.apicore"))
      self$`intakeSettings` <- .setComplexProperty(typeList = list(DataStageDataStreamer, DSSDataStreamer, CatalogDataStreamer, FileSystemDataStreamer, HTTPDataStreamer, JDBCDataStreamer, LocalFileDataStreamer, AzureDataStreamer, GCPDataStreamer, BigQueryDataStreamer, S3DataStreamer, SnowflakeDataStreamer, SynapseDataStreamer), propertyData = BatchPredictionJobSpecResponseObject$intakeSettings)
      self$`maxExplanations` <- BatchPredictionJobSpecResponseObject$`maxExplanations`
      self$`modelId` <- BatchPredictionJobSpecResponseObject$`modelId`
      self$`modelPackageId` <- BatchPredictionJobSpecResponseObject$`modelPackageId`
      self$`numConcurrent` <- BatchPredictionJobSpecResponseObject$`numConcurrent`
      self$`outputSettings` <- .setComplexProperty(typeList = list(FileSystemOutputAdaptor, HttpOutputAdaptor, JdbcOutputAdaptor, LocalFileOutputAdaptor, TableauOutputAdaptor, AzureOutputAdaptor, GCPOutputAdaptor, BigQueryOutputAdaptor, S3OutputAdaptor, SnowflakeOutputAdaptor, SynapseOutputAdaptor), propertyData = BatchPredictionJobSpecResponseObject$outputSettings)
      self$`passthroughColumns` <- ApiClient$new()$deserializeObj(BatchPredictionJobSpecResponseObject$`passthroughColumns`, "array[character]", loadNamespace("datarobot.apicore"))
      self$`passthroughColumnsSet` <- BatchPredictionJobSpecResponseObject$`passthroughColumnsSet`
      self$`pinnedModelId` <- BatchPredictionJobSpecResponseObject$`pinnedModelId`
      self$`predictionInstance` <- BatchPredictionJobPredictionInstance$new()$fromJSON(jsonlite::toJSON(BatchPredictionJobSpecResponseObject$predictionInstance, auto_unbox = TRUE, digits = NA, null = "null"))
      self$`predictionWarningEnabled` <- BatchPredictionJobSpecResponseObject$`predictionWarningEnabled`
      self$`skipDriftTracking` <- BatchPredictionJobSpecResponseObject$`skipDriftTracking`
      self$`thresholdHigh` <- BatchPredictionJobSpecResponseObject$`thresholdHigh`
      self$`thresholdLow` <- BatchPredictionJobSpecResponseObject$`thresholdLow`
      self$`timeseriesSettings` <- .setComplexProperty(typeList = list(BatchPredictionJobTimeSeriesSettingsForecast, BatchPredictionJobTimeSeriesSettingsHistorical), propertyData = BatchPredictionJobSpecResponseObject$timeseriesSettings)

      if (validateParams) {
        self$validate()
      }

      return(self)
    }
  )
)
