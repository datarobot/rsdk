# Copyright 2021-2022 DataRobot, Inc. and its affiliates.
#
# All rights reserved.
#
# DataRobot, Inc.
#
# This is proprietary source code of DataRobot, Inc. and its
# affiliates.

# Public API
#
# DataRobot's Public facing API
#
# The version of the OpenAPI document: 2.29.0
# Contact: api-maintainer@datarobot.com
# Generated by: https://openapi-generator.tech

#' @docType class
#' @title Analytics operations
#' @description datarobot.apicore.Analytics
#' @format An \code{R6Class} generator object
#' @field apiClient Handles the client-server communication.
#'
#' @importFrom R6 R6Class
#' @export
AnalyticsApi <- R6::R6Class(
  "AnalyticsApi",
  public = list(
    apiClient = NULL,

    #' @param apiClient A configurable `ApiClient` instance. If none provided, a new client with default configuration will be created.
    initialize = function(apiClient) {
      if (!missing(apiClient)) {
        self$apiClient <- apiClient
      } else {
        self$apiClient <- ApiClient$new()
      }
    },
    #' @description Retrieve all the available events. DEPRECATED API.
    #' Produces: "application/json"
    #'
    #' @details Retrieve all the available events. DEPRECATED API.
    #' @details This method invokes `GET /eventLogs/events/` in the DataRobot Public API.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{AuditLogsEventListResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** A list of events.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$EventLogsEventsList()
    #' }
    EventLogsEventsList = function(...) {
      apiResponse <- private$EventLogsEventsListWithHttpInfo(...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Retrieve one page of audit log records.
    #' Produces: "application/json"
    #'
    #' @details Retrieve one page of audit log records.
    #' @details This method invokes `GET /eventLogs/` in the DataRobot Public API.
    #' @param projectId character. The project to select log records for.
    #' @param userId character. The user to select log records for.
    #' @param orgId character. The organization to select log records for.
    #' @param event Enum < [Dataset Version Deleted, Datasets Permadelete Executed, Bias And Fairness Per Class Calculated, Custom Task Deploy, Dataset Created, Add New Dataset For Predictions, Organization Perma-Deletion Started, Create account, Project Created, Retraining Policy Started, Decision Flow Created, Experiment Container Fetched, Users Perma-Deletion Canceled, Project Created from Project Export File, Workspace Marked As Deleted In AI Catalog, Rate limit user group changed, Detected Data Quality: Lagged Features, Segment Attributes Specified, Recipe Access Revoked from Organization, User Agreement Accepted, Organization created, Group updated, Models Starred, SHAP Predictions Explanations Preview Computed, Experiment Container References Fetched, Finish Autopilot, Automated Application Shared with Group, Geospatial Feature Transform Created, Data Connection Created, Feature Discovery Relationship Quality Assessment Warnings Metrics, Automated Application Shared with Organization, Project Permadelete Executed, Automated Application Access Revoked from the Group, SHAP Predictions Explanations Computed, Custom inference model updated, Update SAML configuration, Workspace scheduled batch processing job updated, Interaction Feature Deployment Created, Custom Model Conversion Files Uploaded, Period accuracy file validation successful, Logout, User Blueprint Added To Repository, Custom task version added, Automodel Deployment Manually Replaced, Successful Login via Google Idp, Challenger Model Deleted, Comment Deleted, Deployment Permanently Erased, Automodel Deployment Created, Retraining Policy Succeeded, Login Fail, API Key Created, FEAR Predict Job Started, Batch prediction job aborted, MLOps Installer Download Request Received, Activated On First Login, Replaced Model, Invitation sent, Download Model Package, Dataset Shared, Project Access Revoked from the Group, Data Stores Permadelete Submitted, Custom task added, Users Perma-Deletion Submitted, Dataset Deleted, Created dataset version from Data Engine workspace, Child Entity Disassociated From Workspace In AI Catalog, Number of bias mitigation jobs on Autopilot stage., Multi-Factor Auth Enable, Recipe Shared with Group, PPS Docker Image Download Request Received, Workspace Tags Modified, Dataset Version Undeleted, Workspace Scheduled Batch Run Started, Notification channel updated, Detected Data Quality: Inliers, Deployment Deleted, Use Case Attachment Removed, Users Perma-Deletion Preview Building Submitted, No predictors are left because of Do-Not-Derive, Users Perma-Deletion Preview Building Completed, Completed Feature Discovery for Primary Dataset, Custom RBAC Access Role Updated, PredictionIntegrationJob Deleted, User Blueprint Tags Modified, Deployment Humility Rule Updated, Global SAML Configuration Updated, Project Cloned, User Blueprint Created, Restart Autopilot, Automated Application Created, Model Insights Job Submitted, External Predictions Configured, Dataset relationship created, Dataset Reloaded, Challenger Models Enabled, Dataset transform created, Multi-Factor Auth Disable, Project Autopilot Configured, Custom RBAC Access Role Created, Feature Discovery Relationship Quality Assessment Inputs Metrics, Download Model Package From Deployment, Automated Application Deleted, Users Perma-Deletion Failed, Deployment Deactivated, First Login After DR Account Migration, Bias and Fairness monitoring settings updated., Activate account, Approve account, Batch prediction job started, Restore Reduced Features, Users Perma-Deletion Preview Building Started, Compliance Doc Previewed, Reset API Token For User, Default value for Do-Not-Derive is changed, aiAPI Portal Login, Dataset featurelist deleted, RuleFit Code Downloaded, Data engine workspace deleted, Download Codegen From Deployment, Custom RBAC Access Role Deleted, Credential Created, Blueprint Search Executed, Job definition created, Decision Flow Test Downloaded, Recipe Access Revoked from User, Bias And Fairness Insights Calculated, Prime Run, Global SAML Configuration Deleted, Challenger Model Promoted, Project Deleted, Notification channel deleted, Deploy Model To Hadoop, PredictionIntegrationJob Created, Download Chart, Deployment Humility Rule Added, Project Access Revoked from the Organization, Data engine query generator created, Data engine workspace created, Approval Workflow Policy Action, Download Deployment Chart, Organization Perma-Deletion Requested, User Blueprint Description Modified, ADLS OAuth User Login Succeeded, Dataset Categories Modified, Update account, User Blueprint Deleted, Retraining Policy Cancelled, Automated Application Access Revoked from the Organization, Change Request Resolved, Automated Document Deleted, Available Forecast Points Computation Job Started, Data Connection Updated, Experiment Container Deleted , Project Options Retrieved, User Agreement Declined, Workspace Modified, Recipe Access Revoked from Group, Deployment prediction export created, Global SAML Configuration Added, Recipe Shared, Custom Model Conversion Failed, Retraining Policy Failed, Download All Charts, Workspace Scheduled Batch Run Failed, Organization Perma-Deletion Unmarked, Challenger Model Created, Credential Deleted, Project Access Revoked from the User, Experiment Container Entity Unlinked, Pipeline downsampling run failed to start., Download Codegen, Do-Not-Derive is used, Organization deleted, Credential Updated, Challenger Models Disabled, Data Sources Permadelete Failed, Approval Workflow Policy Created, Data Stores Permadelete Executed, API Key Deleted, Child Entity Associated With Workspace In AI Catalog, Notification policy updated, Clustering Cluster Names Updated, Experiment Container Entities Fetched, Custom model item added, Dataset refresh job deleted, Prime Downloaded, SHAP Training Predictions Explanations Computed, Project Description Updated, Dataset Name Modified, Segment Analysis Enabled, Compute Cluster Deleted, ADLS OAuth User Login Started, Automated Document Requested, Deployment Added, Detected Data Quality: Disguised Missing Values, Empty Cluster Status Created, Batch prediction job created, Data Stores Permadelete Failed, Select Model Metric, Request Model Insights, User Blueprint Tasks Retrieved, Deployment training data export created, Organization Perma-Deletion Completed, Automated Document Downloaded, Detected Data Quality: Target Leakage, Decision Flow Model Package Created, Detected Data Quality: Imputation Leakage, Detected Data Quality: Leading or Trailing Series, Data Source is created, Workspace Registered In AI Catalog, Custom Model Conversion Succeeded, Dataset Undeleted, Users Perma-Deletion Started, Actuals Uploaded, User Blueprint Deleted In Bulk, Data engine workspace state previewed, Login Succeeded Via Global SAML SSO, Abort Autopilot, Project Shared with Group, Users Perma-Deletion Completed, Project Exported as Project Export File, Managed Image Built, Dataset Download, Data engine workspace updated, Advanced Tuning Requested, Automated Document Created, Retraining Policy Created, Experiment Container Entity Linked, Compute External Insights, Compliance Doc Generated, Change Request Updated, Non Existent Use Case Attachment Removed, Project Permadelete Submitted, Automated Application Shared, ADLS OAuth Token Renewal Succeeded, Change Request Reopened, PredictionIntegrationJob Updated, Users Perma-Deletion Preview Building Canceled, Challenger Insight Generation Started, Successful Decision Flow Test, Detected Data Quality: Missing Images, PredictionIntegrationJob Completed, Detected Data Quality: Missing Documents, User Append Columns Download With Predictions, Workspace Name Modified, Data Connection Tested, User Blueprint Validated, Organizations Perma-Deletion Requested, Automated Application Duplicated, Experiment Container Updated, Calculation of prediction intervals is requested, Detected Data Quality: Quantile Target Sparsity, Change Request Cancelled, Interaction Feature Created, User Blueprint Name Modified, Data engine query generator deleted, Dataset featurelist updated, Dataset refresh job created, Automated Application Domain Prefix Changed, Failed Decision Flow Test, Completed Feature Discovery Secondary Datasets, Add SAML configuration, Dataset featurelist created, Unsupervised Mode Started, Deactivate Account, Workspace Description Modified, Use Case Updated, Approval Workflow Policy Updated, Batch prediction job completed, Dataset Sharing Removed, Users Perma-Deletion Canceling, Datasets Permadelete Submitted, Workspace Scheduled Batch Run Succeeded, SHAP Impact Computed, User Blueprint Updated, Compute Cluster Added, CCM Balancer Terminated, Train Model, Invitation Accepted, Automated Document Previewed, Successful Login using OIDC token exchange, Organization updated, Recipe Shared with Organization, Detected Data Quality: New Series in Recent Data, Created dataset from Data Engine workspace, Geometry Over Geo Computed, Batch Prediction Created from Dataset, Project Permadelete Failed, Detected Data Quality: Multicategorical Invalid Format, Decision Flow Version Deleted, Association ID Set, ADLS OAuth Token Obtained, Dataset relationship updated, Download Predictions, Dataset Materialized, Custom Task Fit, Users Perma-Deletion Preview Building Canceling, Compliance Doc Deleted, Custom inference model added, Deployment prediction warning setting updated, Detected Data Quality: Quantile Target Zero Inflation, Organization Perma-Deletion Failed, Text prediction explanations computed, Project Restored, Empty Catalog Item Created, Deny account, Deployment Humility Setting Updated, Workspace scheduled batch processing job created, Dataset Upload, User Blueprint Retrieved, Project Created from Dataset, Predictions by Forecast Date Settings Updated, Multilabel Labelwise ROC With Missing TPR Or FPR Requested, API Key Updated, Period accuracy insight computed, Project Shared, Base Image Built, Comment Created, User Blueprints Listed, Retraining Policy Deleted, App Config Changed, Use Case Stage Changed, Data Store Config Request Submitted, Data Sources Permadelete Executed, Project Options Updated, Automated Application Access Revoked from the User, Bulk Datasets Tags Appended, Bias and Fairness protected features specified., Deployment Humility Rule Deleted, Successful Login using OIDC flow, Segment Analysis Used, ADLS OAuth Failed, Dataset for predictions with actual value column processed, Detected Data Quality: Inconsistent Gaps, Download Model, Deployment Activated, Login Success Via SAML SSO, Organization Perma-Deletion Marked, Period accuracy file validation failed, Delete SAML configuration, Dataset Tags Modified, Group created, Bias And Fairness Cross Class Calculated, Compliance Doc Downloaded, Datasets Permadelete Failed, CCM CLUSTER Reprovisioned, General Feedback Submitted, Approval Workflow Policy Deleted, Dataset Upload is Completed, Automated Demo Application Created, Detected Data Quality: Outliers, Deployment Humility Rule Submitted, Dataset Column Aliases Modified, Detected Data Quality: Excess Zero, Experiment Container Created, Add Model, Job definition updated, Project Shared with Organization, Detected Data Quality: Target had infrequent negative values, Workspace scheduled batch processing job deleted, Batch prediction job failed, Use Case Attachment Added, Project Target Selected, Notification channel created, CCM Cluster Terminated, Deployment Statistics Reset, Experiment Containers Listed, Start Autopilot, Model Deployment Shared, Group Members Updated, Compute Reason Codes, Project Renamed, Data Sources Permadelete Submitted, Feature Over Geo Computed, Notification policy deleted, Geospatial Primary Location Column Selected, Group deleted, Change Request Review Added, Custom task updated, CCM Resource Group Created, Users Perma-Deletion Preview Building Failed, User Provisioned From JWT, Pipeline downsampling build and run started., PredictionIntegrationJob Failed, Online Conformal PI Calculation Requested, Bulk Datasets Deleted, Automated Application Upgraded, Access request created, Dataset Description Modified, Use Case Created, Login Successful, Decision Flow Version Created, Change Request Created, Data Connection Deleted, SHAP Matrix Computed, Request External Insights, Dataset refresh job updated, CCM Cluster Created, Comment Updated, Target is set as Do-Not-Derive, Documentation Request, Compute Cluster Updated, Notification policy created, Custom Task Prediction Made, Change password] > The event type of records.
    #' @param minTimestamp character. The lower bound for timestamps. E.g. &#39;2016-12-13T11:12:13.141516Z&#39;.
    #' @param maxTimestamp character. The upper bound for timestamps. E.g. &#39;2016-12-13T11:12:13.141516Z&#39;.
    #' @param offset integer. This many results will be skipped. Defaults to 0.
    #' @param order Enum < [asc, desc] > The order of the results. Defaults to descending.
    #' @param includeIdentifyingFields Enum < [false, False, true, True] > Indicates if identifying information like user names, project names, etc. should be included or not. Defaults to True.
    #' @param auditReportType Enum < [APP_USAGE, ADMIN_USAGE] > Indicates which type of event to return - must be one of &#x60;&#x60;APP_USAGE&#x60;&#x60; for application related events (i.e. Project Created, Dataset Uploaded, etc.) or &#x60;&#x60;ADMIN_USAGE&#x60;&#x60; for admin related events (i.e. Reset API Token for User, Organization Created, etc.). If not provided, all events will be returned by default.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{AuditLogsRetrieveResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** A list of audit log records.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' projectId <- 'projectId_example' # character | The project to select log records for.
    #' userId <- 'userId_example' # character | The user to select log records for.
    #' orgId <- 'orgId_example' # character | The organization to select log records for.
    #' event <- 'event_example' # character | The event type of records.
    #' minTimestamp <- 'minTimestamp_example' # character | The lower bound for timestamps. E.g. '2016-12-13T11:12:13.141516Z'.
    #' maxTimestamp <- 'maxTimestamp_example' # character | The upper bound for timestamps. E.g. '2016-12-13T11:12:13.141516Z'.
    #' offset <- 0 # integer | This many results will be skipped. Defaults to 0.
    #' order <- "desc" # character | The order of the results. Defaults to descending.
    #' includeIdentifyingFields <- "true" # character | Indicates if identifying information like user names, project names, etc. should be included or not. Defaults to True.
    #' auditReportType <- 'auditReportType_example' # character | Indicates which type of event to return - must be one of ``APP_USAGE`` for application related events (i.e. Project Created, Dataset Uploaded, etc.) or ``ADMIN_USAGE`` for admin related events (i.e. Reset API Token for User, Organization Created, etc.). If not provided, all events will be returned by default.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$EventLogsList(projectId=projectId, userId=userId, orgId=orgId, event=event, minTimestamp=minTimestamp, maxTimestamp=maxTimestamp, offset=offset, order=order, includeIdentifyingFields=includeIdentifyingFields, auditReportType=auditReportType)
    #' }
    EventLogsList = function(projectId = NULL, userId = NULL, orgId = NULL, event = NULL, minTimestamp = NULL, maxTimestamp = NULL, offset = 0, order = "desc", includeIdentifyingFields = "true", auditReportType = NULL, ...) {
      apiResponse <- private$EventLogsListWithHttpInfo(projectId, userId, orgId, event, minTimestamp, maxTimestamp, offset, order, includeIdentifyingFields, auditReportType, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Retrieve prediction usage data.
    #' Produces: "application/json"
    #'
    #' @details Retrieve prediction usage data. &#x60;CAN_ACCESS_USER_ACTIVITY&#x60; permission is required.
    #' @details This method invokes `GET /eventLogs/predictionUsage/` in the DataRobot Public API.
    #' @param minTimestamp character. The lower bound for timestamps. E.g. &#39;2016-12-13T11:12:13.141516Z&#39;.
    #' @param maxTimestamp character. The upper bound for timestamps. Time range should not exceed 24 hours. E.g. &#39;2016-12-13T11:12:13.141516Z&#39;.
    #' @param projectId character. The project to retrieve prediction usage for.
    #' @param userId character. The user to retrieve prediction usage for.
    #' @param order Enum < [asc, desc] > The order of prediction usage rows sorted by &#x60;&#x60;timestamp&#x60;&#x60;. Defaults to descending.
    #' @param offset integer. This many results will be skipped. Defaults to 0.
    #' @param includeIdentifyingFields Enum < [false, False, true, True] > Indicates if identifying information like user names, project names, etc should be included or not. Defaults to True.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{PredictionUsageRetrieveResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** A list of prediction events.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' minTimestamp <- 'minTimestamp_example' # character | The lower bound for timestamps. E.g. '2016-12-13T11:12:13.141516Z'.
    #' maxTimestamp <- 'maxTimestamp_example' # character | The upper bound for timestamps. Time range should not exceed 24 hours. E.g. '2016-12-13T11:12:13.141516Z'.
    #' projectId <- 'projectId_example' # character | The project to retrieve prediction usage for.
    #' userId <- 'userId_example' # character | The user to retrieve prediction usage for.
    #' order <- "desc" # character | The order of prediction usage rows sorted by ``timestamp``. Defaults to descending.
    #' offset <- 0 # integer | This many results will be skipped. Defaults to 0.
    #' includeIdentifyingFields <- "true" # character | Indicates if identifying information like user names, project names, etc should be included or not. Defaults to True.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$EventLogsPredictionUsageList(minTimestamp, maxTimestamp, projectId=projectId, userId=userId, order=order, offset=offset, includeIdentifyingFields=includeIdentifyingFields)
    #' }
    EventLogsPredictionUsageList = function(minTimestamp, maxTimestamp, projectId = NULL, userId = NULL, order = "desc", offset = 0, includeIdentifyingFields = "true", ...) {
      apiResponse <- private$EventLogsPredictionUsageListWithHttpInfo(minTimestamp, maxTimestamp, projectId, userId, order, offset, includeIdentifyingFields, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Get audit record by ID.
    #' Produces: "application/json"
    #'
    #' @details Get audit record by ID.
    #' @details This method invokes `GET /eventLogs/{recordId}/` in the DataRobot Public API.
    #' @param recordId character. The id of the audit log.
    #' @param includeIdentifyingFields Enum < [false, False, true, True] > Indicates if identifying information like user names, project names, etc should be included or not. Defaults to True.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{AuditLogsRetrieveOneResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** The queried audit record.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' recordId <- 'recordId_example' # character | The id of the audit log.
    #' includeIdentifyingFields <- "true" # character | Indicates if identifying information like user names, project names, etc should be included or not. Defaults to True.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$EventLogsRetrieve(recordId, includeIdentifyingFields=includeIdentifyingFields)
    #' }
    EventLogsRetrieve = function(recordId, includeIdentifyingFields = "true", ...) {
      apiResponse <- private$EventLogsRetrieveWithHttpInfo(recordId, includeIdentifyingFields, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Create a customer usage data artifact request. Requires \&quot;CAN_ACCESS_USER_ACTIVITY\&quot; permission.
    #' Produces: NA
    #'
    #' @details Create a customer usage data artifact request. Requires \&quot;CAN_ACCESS_USER_ACTIVITY\&quot; permission. Returns async task status URL as a \&quot;Location\&quot; header. Async task status should be polled in order to retrieve artifact id.
    #' @details This method invokes `POST /usageDataExports/` in the DataRobot Public API.
    #' @param usageDataExport \link{UsageDataExport}.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`202`** Customer usage data artifact creation started. Status can be tracked at Location field in headers.
    #' \itemize{
    #' }
    #' \item **`400`** Artifact creation process encountered a problem.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' usageDataExport <- UsageDataExport$new() # UsageDataExport |
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsageDataExportsCreate(usageDataExport=usageDataExport)
    #' }
    UsageDataExportsCreate = function(usageDataExport = NULL, ...) {
      apiResponse <- private$UsageDataExportsCreateWithHttpInfo(usageDataExport, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Retrieve a prepared customer usage data artifact.
    #' Produces: "application/json"
    #'
    #' @details Retrieve a prepared customer usage data artifact. Requires \&quot;CAN_ACCESS_USER_ACTIVITY\&quot; permission.
    #' @details This method invokes `GET /usageDataExports/{artifactId}/` in the DataRobot Public API.
    #' @param artifactId character. The ID of the generated artifact to retrieve.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{UsageDataRetrieveResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`202`** An artifact file in .zip format.
    #' \itemize{
    #' }
    #' \item **`400`** Usage data artifact retrieval failed.
    #' \itemize{
    #' }
    #' \item **`404`** Requested artifact does not exist.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' artifactId <- 'artifactId_example' # character | The ID of the generated artifact to retrieve.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsageDataExportsRetrieve(artifactId)
    #' }
    UsageDataExportsRetrieve = function(artifactId, ...) {
      apiResponse <- private$UsageDataExportsRetrieveWithHttpInfo(artifactId, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Describe supported available audit events with which to filter result data.
    #' Produces: "application/json"
    #'
    #' @details Describe supported available audit events with which to filter result data.
    #' @details This method invokes `GET /usageDataExports/supportedEvents/` in the DataRobot Public API.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{UsageDataEventsListResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** A list of supported available audit events.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsageDataExportsSupportedEventsList()
    #' }
    UsageDataExportsSupportedEventsList = function(...) {
      apiResponse <- private$UsageDataExportsSupportedEventsListWithHttpInfo(...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Reset resource usage for the resource
    #' Produces: NA
    #'
    #' @details Reset rate limit resource usage for a user of a specified resource to zero. This will happen automatically when windows roll over. This route can be used to reset a user&#39;s rate limits sooner.
    #' @details This method invokes `DELETE /users/{userId}/rateLimitUsage/{resourceName}/` in the DataRobot Public API.
    #' @param userId character. The id of the user to reset usage for.
    #' @param resourceName character. The resource name to reset usage for.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`204`** The usage has been successfully reset to zero.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' userId <- 'userId_example' # character | The id of the user to reset usage for.
    #' resourceName <- 'resourceName_example' # character | The resource name to reset usage for.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsersRateLimitUsageDelete(userId, resourceName)
    #' }
    UsersRateLimitUsageDelete = function(userId, resourceName, ...) {
      apiResponse <- private$UsersRateLimitUsageDeleteWithHttpInfo(userId, resourceName, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Reset resource usage for all resources
    #' Produces: NA
    #'
    #' @details Reset specified user&#39;s rate limit resource usage to zero for all resources. When windows roll over, all limits are automatically reset. Use this route to reset usage sooner.
    #' @details This method invokes `DELETE /users/{userId}/rateLimitUsage/` in the DataRobot Public API.
    #' @param userId character. The user identifier.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`204`** The usage has been successfully reset to zero.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' userId <- 'userId_example' # character | The user identifier.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsersRateLimitUsageDeleteMany(userId)
    #' }
    UsersRateLimitUsageDeleteMany = function(userId, ...) {
      apiResponse <- private$UsersRateLimitUsageDeleteManyWithHttpInfo(userId, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description List resource usage for a user
    #' Produces: "application/json"
    #'
    #' @details List the rate limit resource usage for a user. The usage array returned will have one object corresponding to each rate limit applied to the user.
    #' @details This method invokes `GET /users/{userId}/rateLimitUsage/` in the DataRobot Public API.
    #' @param userId character. The user identifier.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{ResourceUsageResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`**
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' userId <- 'userId_example' # character | The user identifier.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsersRateLimitUsageList(userId)
    #' }
    UsersRateLimitUsageList = function(userId, ...) {
      apiResponse <- private$UsersRateLimitUsageListWithHttpInfo(userId, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    }
  ),
  private = list(
    # A helper function to invoke the API operation `EventLogsEventsList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    EventLogsEventsListWithHttpInfo = function(...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      body <- NULL
      urlPath <- "/eventLogs/events/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "AuditLogsEventListResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `EventLogsList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    EventLogsListWithHttpInfo = function(projectId = NULL, userId = NULL, orgId = NULL, event = NULL, minTimestamp = NULL, maxTimestamp = NULL, offset = 0, order = "desc", includeIdentifyingFields = "true", auditReportType = NULL, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      queryParams["projectId"] <- projectId

      queryParams["userId"] <- userId

      queryParams["orgId"] <- orgId

      queryParams["event"] <- event

      queryParams["minTimestamp"] <- minTimestamp

      queryParams["maxTimestamp"] <- maxTimestamp

      queryParams["offset"] <- offset

      queryParams["order"] <- order

      queryParams["includeIdentifyingFields"] <- includeIdentifyingFields

      queryParams["auditReportType"] <- auditReportType

      body <- NULL
      urlPath <- "/eventLogs/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "AuditLogsRetrieveResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `EventLogsPredictionUsageList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    EventLogsPredictionUsageListWithHttpInfo = function(minTimestamp, maxTimestamp, projectId = NULL, userId = NULL, order = "desc", offset = 0, includeIdentifyingFields = "true", ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`minTimestamp`)) {
        stop("Missing required parameter `minTimestamp`.")
      }

      if (missing(`maxTimestamp`)) {
        stop("Missing required parameter `maxTimestamp`.")
      }

      queryParams["projectId"] <- projectId

      queryParams["userId"] <- userId

      queryParams["minTimestamp"] <- minTimestamp

      queryParams["maxTimestamp"] <- maxTimestamp

      queryParams["order"] <- order

      queryParams["offset"] <- offset

      queryParams["includeIdentifyingFields"] <- includeIdentifyingFields

      body <- NULL
      urlPath <- "/eventLogs/predictionUsage/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "PredictionUsageRetrieveResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `EventLogsRetrieve`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    EventLogsRetrieveWithHttpInfo = function(recordId, includeIdentifyingFields = "true", ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`recordId`)) {
        stop("Missing required parameter `recordId`.")
      }

      queryParams["includeIdentifyingFields"] <- includeIdentifyingFields

      body <- NULL
      urlPath <- "/eventLogs/{recordId}/"
      if (!missing(`recordId`)) {
        urlPath <- gsub(paste0("\\{", "recordId", "\\}"), URLencode(as.character(`recordId`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "AuditLogsRetrieveOneResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsageDataExportsCreate`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsageDataExportsCreateWithHttpInfo = function(usageDataExport = NULL, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (!missing(`usageDataExport`) && isa(usageDataExport, c("UsageDataExport", "R6"))) {
        body <- `usageDataExport`$toJSON()
      } else {
        stop("UsageDataExportsCreateWithHttpInfo requires parameter usageDataExport to be of type UsageDataExport.")
      }

      urlPath <- "/usageDataExports/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "POST",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        ApiResponse$new(NULL, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsageDataExportsRetrieve`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsageDataExportsRetrieveWithHttpInfo = function(artifactId, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`artifactId`)) {
        stop("Missing required parameter `artifactId`.")
      }

      body <- NULL
      urlPath <- "/usageDataExports/{artifactId}/"
      if (!missing(`artifactId`)) {
        urlPath <- gsub(paste0("\\{", "artifactId", "\\}"), URLencode(as.character(`artifactId`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "UsageDataRetrieveResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsageDataExportsSupportedEventsList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsageDataExportsSupportedEventsListWithHttpInfo = function(...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      body <- NULL
      urlPath <- "/usageDataExports/supportedEvents/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "UsageDataEventsListResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsersRateLimitUsageDelete`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsersRateLimitUsageDeleteWithHttpInfo = function(userId, resourceName, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`userId`)) {
        stop("Missing required parameter `userId`.")
      }

      if (missing(`resourceName`)) {
        stop("Missing required parameter `resourceName`.")
      }

      body <- NULL
      urlPath <- "/users/{userId}/rateLimitUsage/{resourceName}/"
      if (!missing(`userId`)) {
        urlPath <- gsub(paste0("\\{", "userId", "\\}"), URLencode(as.character(`userId`), reserved = TRUE), urlPath)
      }

      if (!missing(`resourceName`)) {
        urlPath <- gsub(paste0("\\{", "resourceName", "\\}"), URLencode(as.character(`resourceName`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "DELETE",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        ApiResponse$new(NULL, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsersRateLimitUsageDeleteMany`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsersRateLimitUsageDeleteManyWithHttpInfo = function(userId, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`userId`)) {
        stop("Missing required parameter `userId`.")
      }

      body <- NULL
      urlPath <- "/users/{userId}/rateLimitUsage/"
      if (!missing(`userId`)) {
        urlPath <- gsub(paste0("\\{", "userId", "\\}"), URLencode(as.character(`userId`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "DELETE",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        ApiResponse$new(NULL, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsersRateLimitUsageList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsersRateLimitUsageListWithHttpInfo = function(userId, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`userId`)) {
        stop("Missing required parameter `userId`.")
      }

      body <- NULL
      urlPath <- "/users/{userId}/rateLimitUsage/"
      if (!missing(`userId`)) {
        urlPath <- gsub(paste0("\\{", "userId", "\\}"), URLencode(as.character(`userId`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "ResourceUsageResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    }
  )
)
