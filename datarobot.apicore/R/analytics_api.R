# Copyright 2021 DataRobot, Inc. and its affiliates.
#
# All rights reserved.
#
# DataRobot, Inc.
#
# This is proprietary source code of DataRobot, Inc. and its
# affiliates.

# Public API
#
# DataRobot's Public facing API
#
# The version of the OpenAPI document: 2.28.0
# Contact: api-maintainer@datarobot.com
# Generated by: https://openapi-generator.tech

#' @docType class
#' @title Analytics operations
#' @description datarobot.apicore.Analytics
#' @format An \code{R6Class} generator object
#' @field apiClient Handles the client-server communication.
#'
#' @importFrom R6 R6Class
#' @export
AnalyticsApi <- R6::R6Class(
  "AnalyticsApi",
  public = list(
    apiClient = NULL,

    #' @param apiClient A configurable `ApiClient` instance. If none provided, a new client with default configuration will be created.
    initialize = function(apiClient) {
      if (!missing(apiClient)) {
        self$apiClient <- apiClient
      } else {
        self$apiClient <- ApiClient$new()
      }
    },
    #' @description Retrieve all the available events. DEPRECATED API.
    #' Produces: "application/json"
    #'
    #' @details Retrieve all the available events. DEPRECATED API.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{AuditLogsEventListResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** A list of events.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$EventLogsEventsList()
    #' }
    EventLogsEventsList = function(...) {
      apiResponse <- private$EventLogsEventsListWithHttpInfo(...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Retrieve one page of audit log records.
    #' Produces: "application/json"
    #'
    #' @details Retrieve one page of audit log records.
    #' @param projectId character. The project to select log records for.
    #' @param userId character. The user to select log records for.
    #' @param orgId character. The organization to select log records for.
    #' @param event Enum < [Recipe Access Revoked from User, Dataset Name Modified, Automated Document Created, Clustering Cluster Names Updated, Download Model Package, Dataset Created, Deployment Deleted, Update account, Group created, Project Access Revoked from the User, Restart Autopilot, Compliance Doc Downloaded, Invitation sent, Dataset Deleted, Dataset Column Aliases Modified, Non Existent Use Case Attachment Removed, Start Autopilot, Custom inference model updated, Successful Login using OIDC token exchange, Dataset Shared, API Key Created, Models Starred, Delete SAML configuration, Dataset refresh job updated, Custom model item added, Detected Data Quality: Leading or Trailing Series, Pipeline downsampling build and run started., Data Source is created, CCM Cluster Terminated, Train Model, Retraining Policy Cancelled, Compliance Doc Previewed, Workspace Name Modified, Access request created, Users Perma-Deletion Preview Building Submitted, Dataset Download, Dataset Upload is Completed, Credential Deleted, Deployment Humility Setting Updated, Compute Cluster Added, Credential Created, Workspace Modified, Dataset relationship created, Multilabel Labelwise ROC With Missing TPR Or FPR Requested, Workspace Registered In AI Catalog, Recipe Shared, Geospatial Feature Transform Created, Project Shared, Segment Analysis Used, Bias And Fairness Cross Class Calculated, Users Perma-Deletion Preview Building Canceling, Automated Document Downloaded, Recipe Access Revoked from Organization, Project Permadelete Submitted, Notification channel updated, Dataset Tags Modified, Approval Workflow Policy Action, Dataset Reloaded, Workspace scheduled batch processing job created, Automated Document Deleted, Organization deleted, Available Forecast Points Computation Job Started, Dataset featurelist updated, aiAPI Portal Login, Automated Document Requested, Job definition updated, ADLS OAuth User Login Succeeded, Global SAML Configuration Deleted, Batch prediction job completed, Download Predictions, Approval Workflow Policy Updated, Rate limit user group changed, Decision Flow Version Deleted, Dataset featurelist deleted, Feature Over Geo Computed, Use Case Stage Changed, Data Sources Permadelete Executed, Dataset Materialized, User Agreement Accepted, Dataset refresh job created, Change Request Review Added, Challenger Model Deleted, Model Deployment Shared, Download Chart, Project Autopilot Configured, Compliance Doc Deleted, PredictionIntegrationJob Created, Custom RBAC Access Role Deleted, Child Entity Associated With Workspace In AI Catalog, Global SAML Configuration Added, Deployment Permanently Erased, Workspace Scheduled Batch Run Failed, Comment Created, SHAP Impact Computed, Retraining Policy Succeeded, Users Perma-Deletion Canceled, Created dataset version from Data Engine workspace, Segment Analysis Enabled, Custom Model Conversion Failed, Custom task added, Deploy Model To Hadoop, Users Perma-Deletion Preview Building Canceled, Data engine workspace created, User Blueprints Listed, Automated Application Shared with Organization, Deployment Humility Rule Submitted, Data engine workspace updated, Feature Discovery Relationship Quality Assessment Warnings Metrics, Approve account, Custom inference model added, Change Request Reopened, Organization Perma-Deletion Started, Workspace Scheduled Batch Run Succeeded, Project Permadelete Failed, Login Successful, Geospatial Primary Location Column Selected, Decision Flow Created, Download Model Package From Deployment, Online Conformal PI Calculation Requested, Data Connection Updated, Datasets Permadelete Submitted, Dataset Version Deleted, Multi-Factor Auth Disable, Detected Data Quality: New Series in Recent Data, Custom task updated, Datasets Permadelete Executed, Custom Task Prediction Made, User Blueprint Tasks Retrieved, Dataset relationship updated, Interaction Feature Deployment Created, Dataset Description Modified, Dataset featurelist created, Segment Attributes Specified, Prime Downloaded, Automated Application Duplicated, Detected Data Quality: Lagged Features, Batch prediction job created, Custom Task Deploy, Create account, Automated Document Previewed, Automodel Deployment Manually Replaced, Group deleted, Custom RBAC Access Role Created, Project Shared with Organization, Deployment Statistics Reset, Notification channel deleted, Add Model, Unsupervised Mode Started, Data Connection Tested, Deployment Humility Rule Deleted, Predictions by Forecast Date Settings Updated, Add New Dataset For Predictions, ADLS OAuth Token Renewal Succeeded, Data Stores Permadelete Submitted, CCM Cluster Created, Batch prediction job aborted, Number of bias mitigation jobs on Autopilot stage., Recipe Shared with Group, Project Created from Dataset, Custom RBAC Access Role Updated, SHAP Predictions Explanations Computed, Successful Decision Flow Test, Dataset transform created, Users Perma-Deletion Completed, Data engine workspace state previewed, Data Stores Permadelete Executed, ADLS OAuth User Login Started, User Blueprint Name Modified, Deployment Humility Rule Added, Comment Deleted, General Feedback Submitted, Data engine workspace deleted, Decision Flow Model Package Created, Organizations Perma-Deletion Requested, Feature Discovery Relationship Quality Assessment Inputs Metrics, Detected Data Quality: Target Leakage, Update SAML configuration, Change Request Resolved, Reset API Token For User, Deployment Deactivated, PredictionIntegrationJob Deleted, Select Model Metric, Dataset Sharing Removed, Detected Data Quality: Outliers, Geometry Over Geo Computed, Detected Data Quality: Inconsistent Gaps, Approval Workflow Policy Deleted, Project Description Updated, Automodel Deployment Created, Download Codegen From Deployment, Batch prediction job started, Automated Application Deleted, User Blueprint Added To Repository, Deployment prediction warning setting updated, Bias And Fairness Per Class Calculated, Target is set as Do-Not-Derive, Notification channel created, SHAP Matrix Computed, Project Restored, Failed Decision Flow Test, Dataset Upload, First Login After DR Account Migration, Job definition created, Users Perma-Deletion Submitted, Retraining Policy Failed, Project Access Revoked from the Organization, Base Image Built, API Key Deleted, Custom Model Conversion Succeeded, Challenger Models Disabled, Notification policy created, Add SAML configuration, Request External Insights, Notification policy deleted, Abort Autopilot, Organization Perma-Deletion Marked, Empty Catalog Item Created, Data Stores Permadelete Failed, Custom Model Conversion Files Uploaded, Use Case Attachment Removed, Default value for Do-Not-Derive is changed, Recipe Access Revoked from Group, Logout, Batch prediction job failed, Detected Data Quality: Inliers, Project Exported as Project Export File, PredictionIntegrationJob Updated, Data Connection Deleted, Compute External Insights, Organization Perma-Deletion Failed, Restore Reduced Features, Decision Flow Test Downloaded, FEAR Predict Job Started, Automated Demo Application Created, Decision Flow Version Created, Actuals Uploaded, Change password, CCM CLUSTER Reprovisioned, Detected Data Quality: Missing Images, User Append Columns Download With Predictions, User Provisioned From JWT, Project Shared with Group, Deny account, Data engine query generator created, Group Members Updated, Project Renamed, Workspace Scheduled Batch Run Started, Workspace Description Modified, Workspace Tags Modified, PredictionIntegrationJob Completed, Managed Image Built, Data Store Config Request Submitted, PredictionIntegrationJob Failed, Automated Application Shared with Group, Bias And Fairness Insights Calculated, Compliance Doc Generated, Calculation of prediction intervals is requested, Detected Data Quality: Target had infrequent negative values, Users Perma-Deletion Failed, Organization created, Batch Prediction Created from Dataset, Bulk Datasets Deleted, Custom Task Fit, Organization Perma-Deletion Completed, Data engine query generator deleted, Project Created, Bias and Fairness protected features specified., Automated Application Access Revoked from the User, Successful Login using OIDC flow, Pipeline downsampling run failed to start., User Blueprint Tags Modified, Use Case Updated, Do-Not-Derive is used, Compute Cluster Updated, User Blueprint Deleted, Activate account, Users Perma-Deletion Preview Building Completed, Compute Reason Codes, App Config Changed, Detected Data Quality: Excess Zero, Group updated, Detected Data Quality: Multicategorical Invalid Format, Data Connection Created, Use Case Created, Retraining Policy Started, Detected Data Quality: Disguised Missing Values, Completed Feature Discovery for Primary Dataset, Users Perma-Deletion Preview Building Started, Challenger Insight Generation Started, Use Case Attachment Added, Deployment Humility Rule Updated, Download Deployment Chart, Datasets Permadelete Failed, Deployment Added, Text prediction explanations computed, ADLS OAuth Token Obtained, Bias and Fairness monitoring settings updated., Deployment Activated, Bulk Datasets Tags Appended, Multi-Factor Auth Enable, SHAP Predictions Explanations Preview Computed, Invitation Accepted, Created dataset from Data Engine workspace, User Blueprint Description Modified, Prime Run, Finish Autopilot, Recipe Shared with Organization, Organization Perma-Deletion Requested, Change Request Created, Download Codegen, Approval Workflow Policy Created, Dataset for predictions with actual value column processed, Automated Application Created, Successful Login via Google Idp, No predictors are left because of Do-Not-Derive, Retraining Policy Created, Users Perma-Deletion Preview Building Failed, Advanced Tuning Requested, Users Perma-Deletion Canceling, User Blueprint Validated, Detected Data Quality: Quantile Target Sparsity, Notification policy updated, API Key Updated, Dataset Version Undeleted, Project Deleted, Download Model, Challenger Model Promoted, Automated Application Domain Prefix Changed, Custom task version added, Workspace scheduled batch processing job updated, Workspace scheduled batch processing job deleted, External Predictions Configured, Automated Application Shared, PPS Docker Image Download Request Received, Automated Application Access Revoked from the Group, Interaction Feature Created, Dataset Categories Modified, Dataset Undeleted, ADLS OAuth Failed, Documentation Request, User Agreement Declined, Credential Updated, Project Permadelete Executed, Challenger Model Created, Comment Updated, Users Perma-Deletion Started, Compute Cluster Deleted, User Blueprint Retrieved, Login Success Via SAML SSO, Data Sources Permadelete Submitted, Change Request Updated, CCM Resource Group Created, Login Succeeded Via Global SAML SSO, Detected Data Quality: Quantile Target Zero Inflation, Automated Application Access Revoked from the Organization, Global SAML Configuration Updated, Automated Application Upgraded, Download All Charts, Activated On First Login, Workspace Marked As Deleted In AI Catalog, Organization updated, User Blueprint Deleted In Bulk, User Blueprint Updated, Association ID Set, Project Access Revoked from the Group, Retraining Policy Deleted, Login Fail, Project Target Selected, Detected Data Quality: Imputation Leakage, MLOps Installer Download Request Received, Empty Cluster Status Created, Project Cloned, Data Sources Permadelete Failed, Dataset refresh job deleted, Child Entity Disassociated From Workspace In AI Catalog, Replaced Model, Project Created from Project Export File, Organization Perma-Deletion Unmarked, SHAP Training Predictions Explanations Computed, User Blueprint Created, Request Model Insights, Challenger Models Enabled, Change Request Cancelled, Completed Feature Discovery Secondary Datasets, CCM Balancer Terminated] > The event type of records.
    #' @param minTimestamp character. The lower bound for timestamps. E.g. &#39;2016-12-13T11:12:13.141516Z&#39;.
    #' @param maxTimestamp character. The upper bound for timestamps. E.g. &#39;2016-12-13T11:12:13.141516Z&#39;.
    #' @param offset integer. This many results will be skipped. Defaults to 0.
    #' @param order Enum < [asc, desc] > The order of the results. Defaults to descending.
    #' @param includeIdentifyingFields Enum < [false, False, true, True] > Indicates if identifying information like user names, project names, etc. should be included or not. Defaults to True.
    #' @param auditReportType Enum < [APP_USAGE, ADMIN_USAGE] > Indicates which type of event to return - must be one of &#x60;&#x60;APP_USAGE&#x60;&#x60; for application related events (i.e. Project Created, Dataset Uploaded, etc.) or &#x60;&#x60;ADMIN_USAGE&#x60;&#x60; for admin related events (i.e. Reset API Token for User, Organization Created, etc.). If not provided, all events will be returned by default.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{AuditLogsRetrieveResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** A list of audit log records.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' projectId <- 'projectId_example' # character | The project to select log records for.
    #' userId <- 'userId_example' # character | The user to select log records for.
    #' orgId <- 'orgId_example' # character | The organization to select log records for.
    #' event <- 'event_example' # character | The event type of records.
    #' minTimestamp <- 'minTimestamp_example' # character | The lower bound for timestamps. E.g. '2016-12-13T11:12:13.141516Z'.
    #' maxTimestamp <- 'maxTimestamp_example' # character | The upper bound for timestamps. E.g. '2016-12-13T11:12:13.141516Z'.
    #' offset <- 0 # integer | This many results will be skipped. Defaults to 0.
    #' order <- "desc" # character | The order of the results. Defaults to descending.
    #' includeIdentifyingFields <- "true" # character | Indicates if identifying information like user names, project names, etc. should be included or not. Defaults to True.
    #' auditReportType <- 'auditReportType_example' # character | Indicates which type of event to return - must be one of ``APP_USAGE`` for application related events (i.e. Project Created, Dataset Uploaded, etc.) or ``ADMIN_USAGE`` for admin related events (i.e. Reset API Token for User, Organization Created, etc.). If not provided, all events will be returned by default.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$EventLogsList(projectId=projectId, userId=userId, orgId=orgId, event=event, minTimestamp=minTimestamp, maxTimestamp=maxTimestamp, offset=offset, order=order, includeIdentifyingFields=includeIdentifyingFields, auditReportType=auditReportType)
    #' }
    EventLogsList = function(projectId = NULL, userId = NULL, orgId = NULL, event = NULL, minTimestamp = NULL, maxTimestamp = NULL, offset = 0, order = "desc", includeIdentifyingFields = "true", auditReportType = NULL, ...) {
      apiResponse <- private$EventLogsListWithHttpInfo(projectId, userId, orgId, event, minTimestamp, maxTimestamp, offset, order, includeIdentifyingFields, auditReportType, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Retrieve prediction usage data.
    #' Produces: "application/json"
    #'
    #' @details Retrieve prediction usage data. &#x60;&#x60;CAN_ACCESS_USER_ACTIVITY&#x60;&#x60; permission is required.
    #' @param minTimestamp character. The lower bound for timestamps. E.g. &#39;2016-12-13T11:12:13.141516Z&#39;.
    #' @param maxTimestamp character. The upper bound for timestamps. Time range should not exceed 24 hours. E.g. &#39;2016-12-13T11:12:13.141516Z&#39;.
    #' @param projectId character. The project to retrieve prediction usage for.
    #' @param userId character. The user to retrieve prediction usage for.
    #' @param order Enum < [asc, desc] > The order of prediction usage rows sorted by &#x60;&#x60;timestamp&#x60;&#x60;. Defaults to descending.
    #' @param offset integer. This many results will be skipped. Defaults to 0.
    #' @param includeIdentifyingFields Enum < [false, False, true, True] > Indicates if identifying information like user names, project names, etc should be included or not. Defaults to True.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{PredictionUsageRetrieveResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** A list of prediction events.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' minTimestamp <- 'minTimestamp_example' # character | The lower bound for timestamps. E.g. '2016-12-13T11:12:13.141516Z'.
    #' maxTimestamp <- 'maxTimestamp_example' # character | The upper bound for timestamps. Time range should not exceed 24 hours. E.g. '2016-12-13T11:12:13.141516Z'.
    #' projectId <- 'projectId_example' # character | The project to retrieve prediction usage for.
    #' userId <- 'userId_example' # character | The user to retrieve prediction usage for.
    #' order <- "desc" # character | The order of prediction usage rows sorted by ``timestamp``. Defaults to descending.
    #' offset <- 0 # integer | This many results will be skipped. Defaults to 0.
    #' includeIdentifyingFields <- "true" # character | Indicates if identifying information like user names, project names, etc should be included or not. Defaults to True.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$EventLogsPredictionUsageList(minTimestamp, maxTimestamp, projectId=projectId, userId=userId, order=order, offset=offset, includeIdentifyingFields=includeIdentifyingFields)
    #' }
    EventLogsPredictionUsageList = function(minTimestamp, maxTimestamp, projectId = NULL, userId = NULL, order = "desc", offset = 0, includeIdentifyingFields = "true", ...) {
      apiResponse <- private$EventLogsPredictionUsageListWithHttpInfo(minTimestamp, maxTimestamp, projectId, userId, order, offset, includeIdentifyingFields, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Get audit record by ID.
    #' Produces: "application/json"
    #'
    #' @details Get audit record by ID.
    #' @param recordId character. The id of the audit log.
    #' @param includeIdentifyingFields Enum < [false, False, true, True] > Indicates if identifying information like user names, project names, etc should be included or not. Defaults to True.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{AuditLogsRetrieveOneResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** The queried audit record.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' recordId <- 'recordId_example' # character | The id of the audit log.
    #' includeIdentifyingFields <- "true" # character | Indicates if identifying information like user names, project names, etc should be included or not. Defaults to True.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$EventLogsRetrieve(recordId, includeIdentifyingFields=includeIdentifyingFields)
    #' }
    EventLogsRetrieve = function(recordId, includeIdentifyingFields = "true", ...) {
      apiResponse <- private$EventLogsRetrieveWithHttpInfo(recordId, includeIdentifyingFields, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Create a customer usage data artifact request. Requires \&quot;CAN_ACCESS_USER_ACTIVITY\&quot; permission.
    #' Produces: NA
    #'
    #' @details Create a customer usage data artifact request. Requires \&quot;CAN_ACCESS_USER_ACTIVITY\&quot; permission. Returns async task status URL as a \&quot;Location\&quot; header. Async task status should be polled in order to retrieve artifact id.
    #' @param usageDataExport \link{UsageDataExport}.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`202`** Customer usage data artifact creation started. Status can be tracked at Location field in headers.
    #' \itemize{
    #' }
    #' \item **`400`** Artifact creation process encountered a problem.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' usageDataExport <- UsageDataExport$new() # UsageDataExport |
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsageDataExportsCreate(usageDataExport=usageDataExport)
    #' }
    UsageDataExportsCreate = function(usageDataExport = NULL, ...) {
      apiResponse <- private$UsageDataExportsCreateWithHttpInfo(usageDataExport, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Retrieve a prepared customer usage data artifact.
    #' Produces: "application/json"
    #'
    #' @details Retrieve a prepared customer usage data artifact. Requires \&quot;CAN_ACCESS_USER_ACTIVITY\&quot; permission.
    #' @param artifactId character. The ID of the generated artifact to retrieve.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{UsageDataRetrieveResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`202`** An artifact file in .zip format.
    #' \itemize{
    #' }
    #' \item **`400`** Usage data artifact retrieval failed.
    #' \itemize{
    #' }
    #' \item **`404`** Requested artifact does not exist.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' artifactId <- 'artifactId_example' # character | The ID of the generated artifact to retrieve.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsageDataExportsRetrieve(artifactId)
    #' }
    UsageDataExportsRetrieve = function(artifactId, ...) {
      apiResponse <- private$UsageDataExportsRetrieveWithHttpInfo(artifactId, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Describe supported available audit events with which to filter result data.
    #' Produces: "application/json"
    #'
    #' @details Describe supported available audit events with which to filter result data.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{UsageDataEventsListResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`** A list of supported available audit events.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsageDataExportsSupportedEventsList()
    #' }
    UsageDataExportsSupportedEventsList = function(...) {
      apiResponse <- private$UsageDataExportsSupportedEventsListWithHttpInfo(...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Reset resource usage for the resource
    #' Produces: NA
    #'
    #' @details Reset rate limit resource usage for a user of a specified resource to zero. This will happen automatically when windows roll over. This route can be used to reset a user&#39;s rate limits sooner.
    #' @param userId character. The id of the user to reset usage for.
    #' @param resourceName character. The resource name to reset usage for.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`204`** The usage has been successfully reset to zero.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' userId <- 'userId_example' # character | The id of the user to reset usage for.
    #' resourceName <- 'resourceName_example' # character | The resource name to reset usage for.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsersRateLimitUsageDelete(userId, resourceName)
    #' }
    UsersRateLimitUsageDelete = function(userId, resourceName, ...) {
      apiResponse <- private$UsersRateLimitUsageDeleteWithHttpInfo(userId, resourceName, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description Reset resource usage for all resources
    #' Produces: NA
    #'
    #' @details Reset specified user&#39;s rate limit resource usage to zero for all resources. When windows roll over, all limits are automatically reset. Use this route to reset usage sooner.
    #' @param userId character. The user identifier.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`204`** The usage has been successfully reset to zero.
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' userId <- 'userId_example' # character | The user identifier.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsersRateLimitUsageDeleteMany(userId)
    #' }
    UsersRateLimitUsageDeleteMany = function(userId, ...) {
      apiResponse <- private$UsersRateLimitUsageDeleteManyWithHttpInfo(userId, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    },
    #' @description List resource usage for a user
    #' Produces: "application/json"
    #'
    #' @details List the rate limit resource usage for a user. The usage array returned will have one object corresponding to each rate limit applied to the user.
    #' @param userId character. The user identifier.
    #' @param ... Optional. Additional named parameters to be passed downward.
    #' @return \link{ResourceUsageResponse}
    #' @details Response status codes, messages, and headers:
    #' \itemize{
    #' \item **`200`**
    #' \itemize{
    #' }
    #' }
    #' @examples
    #' \dontrun{
    #' library(datarobot.apicore)
    #' userId <- 'userId_example' # character | The user identifier.
    #'
    #' api.instance <- AnalyticsApi$new()
    #' result <- api.instance$UsersRateLimitUsageList(userId)
    #' }
    UsersRateLimitUsageList = function(userId, ...) {
      apiResponse <- private$UsersRateLimitUsageListWithHttpInfo(userId, ...)
      resp <- apiResponse$response
      if (httr::status_code(resp) == 202) {
        # When the DataRobot Public API returns a 202, this means that
        # an asynchronous job or task has been started. The response will
        # not have a body, but will have a Location header pointing to an
        # endpoint for checking that job's status.
        apiResponse
      } else if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        .ReturnResponse(apiResponse$content)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        apiResponse
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        apiResponse
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        apiResponse
      }
    }
  ),
  private = list(
    # A helper function to invoke the API operation `EventLogsEventsList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    EventLogsEventsListWithHttpInfo = function(...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      body <- NULL
      urlPath <- "/eventLogs/events/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "AuditLogsEventListResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `EventLogsList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    EventLogsListWithHttpInfo = function(projectId = NULL, userId = NULL, orgId = NULL, event = NULL, minTimestamp = NULL, maxTimestamp = NULL, offset = 0, order = "desc", includeIdentifyingFields = "true", auditReportType = NULL, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      queryParams["projectId"] <- projectId

      queryParams["userId"] <- userId

      queryParams["orgId"] <- orgId

      queryParams["event"] <- event

      queryParams["minTimestamp"] <- minTimestamp

      queryParams["maxTimestamp"] <- maxTimestamp

      queryParams["offset"] <- offset

      queryParams["order"] <- order

      queryParams["includeIdentifyingFields"] <- includeIdentifyingFields

      queryParams["auditReportType"] <- auditReportType

      body <- NULL
      urlPath <- "/eventLogs/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "AuditLogsRetrieveResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `EventLogsPredictionUsageList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    EventLogsPredictionUsageListWithHttpInfo = function(minTimestamp, maxTimestamp, projectId = NULL, userId = NULL, order = "desc", offset = 0, includeIdentifyingFields = "true", ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`minTimestamp`)) {
        stop("Missing required parameter `minTimestamp`.")
      }

      if (missing(`maxTimestamp`)) {
        stop("Missing required parameter `maxTimestamp`.")
      }

      queryParams["projectId"] <- projectId

      queryParams["userId"] <- userId

      queryParams["minTimestamp"] <- minTimestamp

      queryParams["maxTimestamp"] <- maxTimestamp

      queryParams["order"] <- order

      queryParams["offset"] <- offset

      queryParams["includeIdentifyingFields"] <- includeIdentifyingFields

      body <- NULL
      urlPath <- "/eventLogs/predictionUsage/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "PredictionUsageRetrieveResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `EventLogsRetrieve`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    EventLogsRetrieveWithHttpInfo = function(recordId, includeIdentifyingFields = "true", ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`recordId`)) {
        stop("Missing required parameter `recordId`.")
      }

      queryParams["includeIdentifyingFields"] <- includeIdentifyingFields

      body <- NULL
      urlPath <- "/eventLogs/{recordId}/"
      if (!missing(`recordId`)) {
        urlPath <- gsub(paste0("\\{", "recordId", "\\}"), URLencode(as.character(`recordId`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "AuditLogsRetrieveOneResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsageDataExportsCreate`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsageDataExportsCreateWithHttpInfo = function(usageDataExport = NULL, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (!missing(`usageDataExport`) && isa(usageDataExport, c("UsageDataExport", "R6"))) {
        body <- `usageDataExport`$toJSON()
      } else {
        stop("UsageDataExportsCreateWithHttpInfo requires parameter usageDataExport to be of type UsageDataExport.")
      }

      urlPath <- "/usageDataExports/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "POST",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        ApiResponse$new(NULL, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsageDataExportsRetrieve`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsageDataExportsRetrieveWithHttpInfo = function(artifactId, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`artifactId`)) {
        stop("Missing required parameter `artifactId`.")
      }

      body <- NULL
      urlPath <- "/usageDataExports/{artifactId}/"
      if (!missing(`artifactId`)) {
        urlPath <- gsub(paste0("\\{", "artifactId", "\\}"), URLencode(as.character(`artifactId`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "UsageDataRetrieveResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsageDataExportsSupportedEventsList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsageDataExportsSupportedEventsListWithHttpInfo = function(...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      body <- NULL
      urlPath <- "/usageDataExports/supportedEvents/"

      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "UsageDataEventsListResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsersRateLimitUsageDelete`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsersRateLimitUsageDeleteWithHttpInfo = function(userId, resourceName, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`userId`)) {
        stop("Missing required parameter `userId`.")
      }

      if (missing(`resourceName`)) {
        stop("Missing required parameter `resourceName`.")
      }

      body <- NULL
      urlPath <- "/users/{userId}/rateLimitUsage/{resourceName}/"
      if (!missing(`userId`)) {
        urlPath <- gsub(paste0("\\{", "userId", "\\}"), URLencode(as.character(`userId`), reserved = TRUE), urlPath)
      }

      if (!missing(`resourceName`)) {
        urlPath <- gsub(paste0("\\{", "resourceName", "\\}"), URLencode(as.character(`resourceName`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "DELETE",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        ApiResponse$new(NULL, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsersRateLimitUsageDeleteMany`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsersRateLimitUsageDeleteManyWithHttpInfo = function(userId, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`userId`)) {
        stop("Missing required parameter `userId`.")
      }

      body <- NULL
      urlPath <- "/users/{userId}/rateLimitUsage/"
      if (!missing(`userId`)) {
        urlPath <- gsub(paste0("\\{", "userId", "\\}"), URLencode(as.character(`userId`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "DELETE",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        ApiResponse$new(NULL, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    },
    # A helper function to invoke the API operation `UsersRateLimitUsageList`. This function is responsible for
    # validating request parameters, building the request, deserializing the response, and handling errors.
    UsersRateLimitUsageListWithHttpInfo = function(userId, ...) {
      args <- list(...)
      queryParams <- list()
      headerParams <- c()

      if (missing(`userId`)) {
        stop("Missing required parameter `userId`.")
      }

      body <- NULL
      urlPath <- "/users/{userId}/rateLimitUsage/"
      if (!missing(`userId`)) {
        urlPath <- gsub(paste0("\\{", "userId", "\\}"), URLencode(as.character(`userId`), reserved = TRUE), urlPath)
      }


      resp <- self$apiClient$CallApi(
        url = paste0(self$apiClient$basePath, urlPath),
        method = "GET",
        queryParams = queryParams,
        headerParams = headerParams,
        body = body,
        ...
      )

      if (httr::status_code(resp) >= 200 && httr::status_code(resp) <= 299) {
        deserializedRespObj <- self$apiClient$deserialize(resp, "ResourceUsageResponse", loadNamespace("datarobot.apicore"))
        ApiResponse$new(deserializedRespObj, resp)
      } else if (httr::status_code(resp) >= 300 && httr::status_code(resp) <= 399) {
        ApiResponse$new(paste("Server returned ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 400 && httr::status_code(resp) <= 499) {
        ApiResponse$new(paste("API client error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      } else if (httr::status_code(resp) >= 500 && httr::status_code(resp) <= 599) {
        ApiResponse$new(paste("API server error with ", httr::status_code(resp), " response status code. See $response for more detail."), resp)
      }
    }
  )
)
