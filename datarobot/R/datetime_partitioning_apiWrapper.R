# Copyright 2021 DataRobot, Inc. and its affiliates.
#
# All rights reserved.
#
# DataRobot, Inc.
#
# This is proprietary source code of DataRobot, Inc. and its
# affiliates.

# Public API
#
# DataRobot's Public facing API
#
# The version of the OpenAPI document: 2.28.0
# Contact: api-maintainer@datarobot.com
# Generated by: https://openapi-generator.tech


# NOTE: This file is auto generated by OpenAPI Generator (https://openapi-generator.tech).
# Do not edit the file manually.

# API Wrapper methods for DatetimePartitioning
# To use these methods without modification, DR endpoint and token
# should be set as environment variables. This will automatically
# happen when you call `datarobot::ConnectToDataRobot()`.



#' CreateProjectsDatetimePartitioning
#'
#' Preview the fully specified datetime partitioning generated by the requested configuration.
#'
#' Preview the fully specified datetime partitioning generated by the requested configuration.  Populates the full datetime partitioning that would be used if the same arguments were passed to :http:patch:`/api/v2/projects/(projectId)/aim/` based on the requested configuration, generating defaults for all non-specified values, so that potential configurations can be tested prior to setting the target and applying a configuration.  `useTimeSeries` controls whether a time series project should be created or a normal project that uses datetime partitioning. See :ref:`Time-Series Projects<time_series_overview>` for more detail on the differences between time series projects and datetime partitioned projects. Time-series projects are only available to some users and use the additional settings of `featureDerivationWindowStart` and `featureDerivationWindowEnd` to establish feature derivation window and `forecastWindowStart` and `forecastWindowEnd` to establish a forecast window. The overview referenced above provides more information about using feature derivation and forecast windows.  When specifying a feature derivation window of a forecast window, the number of units it spans (end - start) must be an integer multiple of the timeStep of the datetimePartitionColumn.  All durations and datetimes should be specified in accordance with the :ref:`timestamp and duration formatting rules<time_format>`.
#'
#' @seealso The method ProjectsDatetimePartitioningCreate in [datarobot.apicore::DatetimePartitioningApi], which this function wraps.
#' @family DatetimePartitioning
#' @export
CreateProjectsDatetimePartitioning <- function(aggregationType, holdoutEndDate, featureDerivationWindowEnd, autopilotDataSelectionMethod, periodicities, datetimePartitionColumn, featureSettings, treatAsExponential, differencingMethod, multiseriesIdColumns, forecastWindowStart, unsupervisedType, defaultToKnownInAdvance, isHoldoutModified, backtests, gapDuration, defaultToAPriori, defaultToDoNotDerive, autopilotClusterList, forecastWindowEnd, calendarId, crossSeriesGroupByColumns, windowsBasisUnit, holdoutDuration, holdoutStartDate, validationDuration, numberOfBacktests, projectId, featureDerivationWindowStart, allowPartialHistoryTimeSeriesPredictions = FALSE, modelSplits = 5, useCrossSeriesFeatures = FALSE, disableHoldout = FALSE, unsupervisedMode = FALSE, useSupervisedFeatureReduction = TRUE, useTimeSeries = FALSE, ...) {
  datetimePartitioningDataForOpenApi <- datarobot.apicore::DatetimePartitioningDataForOpenApi$new(aggregationType = aggregationType, allowPartialHistoryTimeSeriesPredictions = allowPartialHistoryTimeSeriesPredictions, holdoutEndDate = holdoutEndDate, modelSplits = modelSplits, featureDerivationWindowEnd = featureDerivationWindowEnd, autopilotDataSelectionMethod = autopilotDataSelectionMethod, periodicities = periodicities, datetimePartitionColumn = datetimePartitionColumn, useCrossSeriesFeatures = useCrossSeriesFeatures, featureSettings = featureSettings, disableHoldout = disableHoldout, treatAsExponential = treatAsExponential, differencingMethod = differencingMethod, multiseriesIdColumns = multiseriesIdColumns, forecastWindowStart = forecastWindowStart, unsupervisedType = unsupervisedType, defaultToKnownInAdvance = defaultToKnownInAdvance, isHoldoutModified = isHoldoutModified, backtests = backtests, gapDuration = gapDuration, defaultToAPriori = defaultToAPriori, unsupervisedMode = unsupervisedMode, defaultToDoNotDerive = defaultToDoNotDerive, autopilotClusterList = autopilotClusterList, forecastWindowEnd = forecastWindowEnd, calendarId = calendarId, crossSeriesGroupByColumns = crossSeriesGroupByColumns, windowsBasisUnit = windowsBasisUnit, holdoutDuration = holdoutDuration, useSupervisedFeatureReduction = useSupervisedFeatureReduction, holdoutStartDate = holdoutStartDate, validationDuration = validationDuration, useTimeSeries = useTimeSeries, numberOfBacktests = numberOfBacktests, featureDerivationWindowStart = featureDerivationWindowStart, validateParams = TRUE)
  return(datarobot.apicore::DatetimePartitioningApi$new()$ProjectsDatetimePartitioningCreate(datetimePartitioningDataForOpenApi = datetimePartitioningDataForOpenApi, projectId = projectId))
}

#' GetDatetimePartition
#'
#' Retrieve datetime partitioning configuration.
#'
#' Retrieve datetime partitioning configuration  The datetime partition object in the response describes the full partitioning parameters. Since it becomes available after the target has been fully specified and the project is ready for modeling, there are some additional fields available compared to the response from :http:post:`/api/v2/projects/(projectId)/datetimePartitioning/`.  The available training data corresponds to all the data available for training, while the primary training data corresponds to the data that can be used to train while ensuring that all backtests are available. If a model is trained with more data than is available in the primary training data, then all backtests may not have scores available.  All durations and datetimes will be specified in accordance with the :ref:`timestamp and duration formatting rules<time_format>`.
#'
#' @seealso The method ProjectsDatetimePartitioningList in [datarobot.apicore::DatetimePartitioningApi], which this function wraps.
#' @family DatetimePartitioning
#' @export
GetDatetimePartition <- function(project, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "datetimePartitioning")
  # start of generated addition
  # end of generated addition
  part <- DataRobotGET(routeString)
  part$cvMethod <- cvMethods$DATETIME
  as.dataRobotDatetimePartition(part)
}

#' CreateProjectsOptimizedDatetimePartitionings
#'
#' Create an optimized datetime partitioning configuration using the target.
#'
#' Create an optimized datetime partitioning configuration using the target.  Initializes a job to construct an optimized datetime partitioning using the date and target information to ensure that backtests sufficiently cover regions of interest in the target. This is an asynchronous job. The results of the asynchronous job (backtests and other parameters can be used in the synchronous version.  `useTimeSeries` controls whether a time series project should be created or a normal project that uses datetime partitioning. See :ref:`Time-Series Projects<time_series_overview>` for more detail on the differences between time series projects and datetime partitioned projects. Time-series projects are only available to some users and use the additional settings of `featureDerivationWindowStart` and `featureDerivationWindowEnd` to establish feature derivation window and `forecastWindowStart` and `forecastWindowEnd` to establish a forecast window. The overview referenced above provides more information about using feature derivation and forecast windows.  When specifying a feature derivation window of a forecast window, the number of units it spans (end - start) must be an integer multiple of the timeStep of the datetimePartitionColumn.  All durations and datetimes should be specified in accordance with the :ref:`timestamp and duration formatting rules<time_format>`.
#'
#' @seealso The method ProjectsOptimizedDatetimePartitioningsCreate in [datarobot.apicore::DatetimePartitioningApi], which this function wraps.
#' @family DatetimePartitioning
#' @export
CreateProjectsOptimizedDatetimePartitionings <- function(aggregationType, holdoutEndDate, featureDerivationWindowEnd, autopilotDataSelectionMethod, periodicities, datetimePartitionColumn, featureSettings, treatAsExponential, differencingMethod, multiseriesIdColumns, forecastWindowStart, unsupervisedType, defaultToKnownInAdvance, isHoldoutModified, backtests, gapDuration, defaultToAPriori, target, defaultToDoNotDerive, autopilotClusterList, forecastWindowEnd, calendarId, crossSeriesGroupByColumns, windowsBasisUnit, holdoutDuration, holdoutStartDate, validationDuration, numberOfBacktests, projectId, featureDerivationWindowStart, allowPartialHistoryTimeSeriesPredictions = FALSE, modelSplits = 5, useCrossSeriesFeatures = FALSE, disableHoldout = FALSE, unsupervisedMode = FALSE, useSupervisedFeatureReduction = TRUE, useTimeSeries = FALSE, ...) {
  optimizedDatetimePartitioningData <- datarobot.apicore::OptimizedDatetimePartitioningData$new(aggregationType = aggregationType, allowPartialHistoryTimeSeriesPredictions = allowPartialHistoryTimeSeriesPredictions, holdoutEndDate = holdoutEndDate, modelSplits = modelSplits, featureDerivationWindowEnd = featureDerivationWindowEnd, autopilotDataSelectionMethod = autopilotDataSelectionMethod, periodicities = periodicities, datetimePartitionColumn = datetimePartitionColumn, useCrossSeriesFeatures = useCrossSeriesFeatures, featureSettings = featureSettings, disableHoldout = disableHoldout, treatAsExponential = treatAsExponential, differencingMethod = differencingMethod, multiseriesIdColumns = multiseriesIdColumns, forecastWindowStart = forecastWindowStart, unsupervisedType = unsupervisedType, defaultToKnownInAdvance = defaultToKnownInAdvance, isHoldoutModified = isHoldoutModified, backtests = backtests, gapDuration = gapDuration, defaultToAPriori = defaultToAPriori, unsupervisedMode = unsupervisedMode, target = target, defaultToDoNotDerive = defaultToDoNotDerive, autopilotClusterList = autopilotClusterList, forecastWindowEnd = forecastWindowEnd, calendarId = calendarId, crossSeriesGroupByColumns = crossSeriesGroupByColumns, windowsBasisUnit = windowsBasisUnit, holdoutDuration = holdoutDuration, useSupervisedFeatureReduction = useSupervisedFeatureReduction, holdoutStartDate = holdoutStartDate, validationDuration = validationDuration, useTimeSeries = useTimeSeries, numberOfBacktests = numberOfBacktests, featureDerivationWindowStart = featureDerivationWindowStart, validateParams = TRUE)
  return(datarobot.apicore::DatetimePartitioningApi$new()$ProjectsOptimizedDatetimePartitioningsCreate(optimizedDatetimePartitioningData = optimizedDatetimePartitioningData, projectId = projectId))
}

#' ListProjectsOptimizedDatetimePartitionings
#'
#' List all created optimized datetime partitioning configurations
#'
#' List all created optimized datetime partitioning configurations
#'
#' @seealso The method ProjectsOptimizedDatetimePartitioningsList in [datarobot.apicore::DatetimePartitioningApi], which this function wraps.
#' @family DatetimePartitioning
#' @export
ListProjectsOptimizedDatetimePartitionings <- function(projectId, offset = 0, limit = 10, ...) {
  return(datarobot.apicore::DatetimePartitioningApi$new()$ProjectsOptimizedDatetimePartitioningsList(offset = offset, limit = limit, projectId = projectId))
}

#' RetrieveProjectsOptimizedDatetimePartitionings
#'
#' Retrieve optimized datetime partitioning configuration
#'
#' Retrieve optimized datetime partitioning configuration  The optimized datetime partition objects are structurally identical to the original datetime partition objects, however they are retrieved from a mongo database after creation as opposed to being calculated synchronously. The datetime partition object in the response describes the full partitioning parameters.  The available training data corresponds to all the data available for training, while the primary training data corresponds to the data that can be used to train while ensuring that all backtests are available. If a model is trained with more data than is available in the primary training data, then all backtests may not have scores available.  .. note:: All durations and datetimes should be specified in accordance with the :ref:`timestamp and duration formatting rules <time_format>`.
#'
#' @seealso The method ProjectsOptimizedDatetimePartitioningsRetrieve in [datarobot.apicore::DatetimePartitioningApi], which this function wraps.
#' @family DatetimePartitioning
#' @export
RetrieveProjectsOptimizedDatetimePartitionings <- function(datetimePartitioningId, projectId, ...) {
  return(datarobot.apicore::DatetimePartitioningApi$new()$ProjectsOptimizedDatetimePartitioningsRetrieve(datetimePartitioningId = datetimePartitioningId, projectId = projectId))
}

#' DownloadTimeSeriesFeatureDerivationLog
#'
#' Retrieve a text file containing the time series project feature log
#'
#' Retrieve a text file containing the time series project feature log.  The Time Series Feature Log provides details about the feature generation process for a time series project. It includes information about which features are generated and their priority,as well as the detected properties of the time series data such as whether the series is stationary, and periodicities detected.  This route is only supported for time series projects that have finished partitioning.  The feature derivation log will include information about:  * Maximum number of feature to be generated, e.g., ``Limit on the maximum number of feature in this project is 500`` * Number of derived features tested during the feature generation process, e.g., ``Total number of derived features during the feature generation process is 571`` * Number of generated features removed during the feature reduction process e.g. ``Total number of features removed during the feature reduction process is 472`` * Number of remaining features after the combined feature generation and reduction process, e.g., ``The finalized number of features is 99`` * Detected stationarity of the series, e.g., ``Series detected as non-stationary`` * Detected presence of multiplicative trend in the series, e.g., ``Multiplicative trend detected`` * Detected periodicities in the series, e.g., ``Detected periodicities: 7 day`` * Window sizes used in rolling statistics / lag extractors, e.g., ``The window sizes chosen to be: 2 months (because the time step is 1 month and Feature Derivation Window is 2 months)`` * Features that are specified as known-in-advance, e.g., ``Variables treated as apriori: holiday`` * Details about why certain variables are transformed in the input data, e.g., ``Generating variable \"y (log)\" from \"y\" because multiplicative trend is detected`` * Details about features generated as time series features, and their priority, e.g., ``Generating feature \"date (actual)\" from \"date\" (priority: 1)``
#'
#' @seealso The method ProjectsTimeSeriesFeatureLogFileList in [datarobot.apicore::DatetimePartitioningApi], which this function wraps.
#' @family DatetimePartitioning
#' @export
DownloadTimeSeriesFeatureDerivationLog <- function(project, file, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "timeSeriesFeatureLog", "file")
  # start of generated addition
  # end of generated addition
  response <- DataRobotGET(routeString, as = "file", filename = file)
  invisible(NULL)
}

#' GetTimeSeriesFeatureDerivationLog
#'
#' Retrieve the feature derivation log content and log length for a time series project as JSON.
#'
#' Retrieve the feature derivation log content and log length for a time series project as JSON.  The Time Series Feature Log provides details about the feature generation process for a time series project. It includes information about which features are generated and their priority,as well as the detected properties of the time series data such as whether the series is stationary, and periodicities detected.  This route is only supported for time series projects that have finished partitioning.  The feature derivation log will include information about:  * Detected stationarity of the series, e.g., ``Series detected as non-stationary`` * Detected presence of multiplicative trend in the series, e.g., ``Multiplicative trend detected`` * Detected periodicities in the series, e.g., ``Detected periodicities: 7 day`` * Maximum number of feature to be generated, e.g., ``Maximum number of feature to be generated is 1440`` * Window sizes used in rolling statistics / lag extractors, e.g., ``The window sizes chosen to be: 2 months`` * Features that are specified as known-in-advance, e.g., ``Variables treated as apriori: holiday`` * Details about features generated as timeseries features, and their priority, e.g., ``Generating feature \"date (actual)\" from \"date\" (priority: 1)`` * Details about why certain variables are transformed in the input data, e.g., ``Generating variable \"y (log)\" from \"y\" because multiplicative trend is detected``
#'
#' @seealso The method ProjectsTimeSeriesFeatureLogList in [datarobot.apicore::DatetimePartitioningApi], which this function wraps.
#' @family DatetimePartitioning
#' @export
GetTimeSeriesFeatureDerivationLog <- function(project, offset = NULL, limit = NULL, ...) {
  body <- list()
  if (!is.null(offset)) {
    body$offset <- offset
  }
  if (!is.null(limit)) {
    body$limit <- limit
  }
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "timeSeriesFeatureLog")
  # start of generated addition
  # end of generated addition
  featureData <- DataRobotGET(routeString, body = body)
  featureData$featureLog
}
