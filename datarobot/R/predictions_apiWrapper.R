# Copyright 2021 DataRobot, Inc. and its affiliates.
#
# All rights reserved.
#
# DataRobot, Inc.
#
# This is proprietary source code of DataRobot, Inc. and its
# affiliates.

# Public API
#
# DataRobot's Public facing API
#
# The version of the OpenAPI document: 2.28.0
# Contact: api-maintainer@datarobot.com
# Generated by: https://openapi-generator.tech


# NOTE: This file is auto generated by OpenAPI Generator (https://openapi-generator.tech).
# Do not edit the file manually.

# API Wrapper methods for Predictions
# To use these methods without modification, DR endpoint and token
# should be set as environment variables. This will automatically
# happen when you call `datarobot::ConnectToDataRobot()`.



#' CreateBatchPredictionJobDefinitions
#'
#' Creates a new Batch Prediction job definition
#'
#' Create a Batch Prediction Job definition. A configuration for a Batch Prediction job which can either be executed manually upon request or on scheduled intervals, if enabled. The API payload is the same as for `/batchPredictions` along with optional ``enabled`` and ``schedule`` items.
#'
#' @seealso The method BatchPredictionJobDefinitionsCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
CreateBatchPredictionJobDefinitions <- function(columnNamesRemapping, timeseriesSettings, modelId, passthroughColumns, outputSettings, enabled, predictionWarningEnabled, intakeSettings, deploymentId, predictionInstance, csvSettings, chunkSize, modelPackageId, schedule, numConcurrent, passthroughColumnsSet, explanationAlgorithm, name, thresholdHigh, thresholdLow, pinnedModelId, includeProbabilitiesClasses = c(), includePredictionStatus = FALSE, skipDriftTracking = FALSE, disableRowLevelErrorHandling = FALSE, abortOnError = TRUE, maxExplanations = 0, includeProbabilities = TRUE, ...) {
  batchPredictionJobDefinitionsCreate <- datarobot.apicore::BatchPredictionJobDefinitionsCreate$new(columnNamesRemapping = columnNamesRemapping, timeseriesSettings = timeseriesSettings, modelId = modelId, passthroughColumns = passthroughColumns, includeProbabilitiesClasses = includeProbabilitiesClasses, outputSettings = outputSettings, enabled = enabled, predictionWarningEnabled = predictionWarningEnabled, intakeSettings = intakeSettings, includePredictionStatus = includePredictionStatus, deploymentId = deploymentId, skipDriftTracking = skipDriftTracking, predictionInstance = predictionInstance, csvSettings = csvSettings, disableRowLevelErrorHandling = disableRowLevelErrorHandling, abortOnError = abortOnError, chunkSize = chunkSize, modelPackageId = modelPackageId, schedule = schedule, maxExplanations = maxExplanations, numConcurrent = numConcurrent, includeProbabilities = includeProbabilities, passthroughColumnsSet = passthroughColumnsSet, explanationAlgorithm = explanationAlgorithm, name = name, thresholdHigh = thresholdHigh, thresholdLow = thresholdLow, pinnedModelId = pinnedModelId, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionJobDefinitionsCreate(batchPredictionJobDefinitionsCreate = batchPredictionJobDefinitionsCreate))
}

#' DeleteBatchPredictionJobDefinitions
#'
#' Delete Batch Prediction job definition
#'
#' Delete a Batch Prediction job definition
#'
#' @seealso The method BatchPredictionJobDefinitionsDelete in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
DeleteBatchPredictionJobDefinitions <- function(jobDefinitionId, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionJobDefinitionsDelete(jobDefinitionId = jobDefinitionId))
}

#' ListBatchPredictionJobDefinitions
#'
#' List Batch Prediction job definitions
#'
#' List all Batch Prediction jobs definitions available
#'
#' @seealso The method BatchPredictionJobDefinitionsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListBatchPredictionJobDefinitions <- function(deploymentId, offset = 0, limit = 100, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionJobDefinitionsList(offset = offset, deploymentId = deploymentId, limit = limit))
}

#' PatchBatchPredictionJobDefinitions
#'
#' Update Batch Prediction job definition
#'
#' Update a Batch Prediction job definition
#'
#' @seealso The method BatchPredictionJobDefinitionsPatch in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
PatchBatchPredictionJobDefinitions <- function(columnNamesRemapping, timeseriesSettings, modelId, passthroughColumns, outputSettings, enabled, predictionWarningEnabled, intakeSettings, deploymentId, predictionInstance, csvSettings, jobDefinitionId, chunkSize, modelPackageId, schedule, numConcurrent, passthroughColumnsSet, explanationAlgorithm, name, thresholdHigh, thresholdLow, pinnedModelId, includeProbabilitiesClasses = c(), includePredictionStatus = FALSE, skipDriftTracking = FALSE, disableRowLevelErrorHandling = FALSE, abortOnError = TRUE, maxExplanations = 0, includeProbabilities = TRUE, ...) {
  batchPredictionJobDefinitionsUpdate <- datarobot.apicore::BatchPredictionJobDefinitionsUpdate$new(columnNamesRemapping = columnNamesRemapping, timeseriesSettings = timeseriesSettings, modelId = modelId, passthroughColumns = passthroughColumns, includeProbabilitiesClasses = includeProbabilitiesClasses, outputSettings = outputSettings, enabled = enabled, predictionWarningEnabled = predictionWarningEnabled, intakeSettings = intakeSettings, includePredictionStatus = includePredictionStatus, deploymentId = deploymentId, skipDriftTracking = skipDriftTracking, predictionInstance = predictionInstance, csvSettings = csvSettings, disableRowLevelErrorHandling = disableRowLevelErrorHandling, abortOnError = abortOnError, chunkSize = chunkSize, modelPackageId = modelPackageId, schedule = schedule, maxExplanations = maxExplanations, numConcurrent = numConcurrent, includeProbabilities = includeProbabilities, passthroughColumnsSet = passthroughColumnsSet, explanationAlgorithm = explanationAlgorithm, name = name, thresholdHigh = thresholdHigh, thresholdLow = thresholdLow, pinnedModelId = pinnedModelId, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionJobDefinitionsPatch(batchPredictionJobDefinitionsUpdate = batchPredictionJobDefinitionsUpdate, jobDefinitionId = jobDefinitionId))
}

#' ListBatchPredictionJobDefinitionsPortable
#'
#' Retrieve job definition snippet for PBP
#'
#' Retrieve a Batch Prediction job definition for Portable Batch Predictions
#'
#' @seealso The method BatchPredictionJobDefinitionsPortableList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListBatchPredictionJobDefinitionsPortable <- function(jobDefinitionId, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionJobDefinitionsPortableList(jobDefinitionId = jobDefinitionId))
}

#' RetrieveBatchPredictionJobDefinitions
#'
#' Retrieve Batch Prediction job definition
#'
#' Retrieve a Batch Prediction job definition
#'
#' @seealso The method BatchPredictionJobDefinitionsRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
RetrieveBatchPredictionJobDefinitions <- function(jobDefinitionId, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionJobDefinitionsRetrieve(jobDefinitionId = jobDefinitionId))
}

#' CreateBatchPredictions
#'
#' Creates a new Batch Prediction job
#'
#' Submit the configuration for the job and it will be submitted to the queue
#'
#' @seealso The method BatchPredictionsCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
CreateBatchPredictions <- function(columnNamesRemapping, timeseriesSettings, chunkSize, modelId, passthroughColumns, modelPackageId, outputSettings, numConcurrent, predictionWarningEnabled, intakeSettings, passthroughColumnsSet, explanationAlgorithm, deploymentId, thresholdHigh, thresholdLow, predictionInstance, pinnedModelId, csvSettings, disableRowLevelErrorHandling = FALSE, abortOnError = TRUE, includeProbabilitiesClasses = c(), maxExplanations = 0, includeProbabilities = TRUE, includePredictionStatus = FALSE, skipDriftTracking = FALSE, ...) {
  batchPredictionJobCreate <- datarobot.apicore::BatchPredictionJobCreate$new(disableRowLevelErrorHandling = disableRowLevelErrorHandling, abortOnError = abortOnError, columnNamesRemapping = columnNamesRemapping, timeseriesSettings = timeseriesSettings, chunkSize = chunkSize, modelId = modelId, passthroughColumns = passthroughColumns, includeProbabilitiesClasses = includeProbabilitiesClasses, modelPackageId = modelPackageId, outputSettings = outputSettings, maxExplanations = maxExplanations, numConcurrent = numConcurrent, predictionWarningEnabled = predictionWarningEnabled, includeProbabilities = includeProbabilities, intakeSettings = intakeSettings, passthroughColumnsSet = passthroughColumnsSet, explanationAlgorithm = explanationAlgorithm, includePredictionStatus = includePredictionStatus, deploymentId = deploymentId, thresholdHigh = thresholdHigh, thresholdLow = thresholdLow, skipDriftTracking = skipDriftTracking, predictionInstance = predictionInstance, pinnedModelId = pinnedModelId, csvSettings = csvSettings, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsCreate(batchPredictionJobCreate = batchPredictionJobCreate))
}

#' CreateBatchPredictionsCsvUploadFinalizeMultipart
#'
#' Finalize a multipart upload
#'
#' Finalize a multipart upload, indicating that no further chunks will be sent
#'
#' @seealso The method BatchPredictionsCsvUploadFinalizeMultipartCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
CreateBatchPredictionsCsvUploadFinalizeMultipart <- function(predictionJobId, partNumber = 0, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsCsvUploadFinalizeMultipartCreate(predictionJobId = predictionJobId, partNumber = partNumber))
}

#' PutBatchPredictionsCsvUploadPart
#'
#' Upload CSV data in multiple parts
#'
#' Stream CSV data to the prediction job in many parts.Only available for jobs that uses the localFile intake option.
#'
#' @seealso The method BatchPredictionsCsvUploadPartPut in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
PutBatchPredictionsCsvUploadPart <- function(predictionJobId, partNumber = 0, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsCsvUploadPartPut(predictionJobId = predictionJobId, partNumber = partNumber))
}

#' PutManyBatchPredictionsCsvUpload
#'
#' Creates a new_model_id Batch Prediction job
#'
#' Stream CSV data to the prediction job. Only available for jobs thatuses the localFile intake option.
#'
#' @seealso The method BatchPredictionsCsvUploadPutMany in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
PutManyBatchPredictionsCsvUpload <- function(predictionJobId, partNumber = 0, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsCsvUploadPutMany(predictionJobId = predictionJobId, partNumber = partNumber))
}

#' DeleteBatchPredictions
#'
#' Cancel a Batch Prediction job
#'
#' If the job is running, it will be aborted. Then it will be removed, meaning all underlying data will be deleted and the job is removed from the list of jobs.
#'
#' @seealso The method BatchPredictionsDelete in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
DeleteBatchPredictions <- function(predictionJobId, partNumber = 0, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsDelete(predictionJobId = predictionJobId, partNumber = partNumber))
}

#' ListBatchPredictionsDownload
#'
#' Download the scored data set of a batch prediction job
#'
#' This is only valid for jobs scored using the \"localFile\" output option
#'
#' @seealso The method BatchPredictionsDownloadList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListBatchPredictionsDownload <- function(predictionJobId, partNumber = 0, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsDownloadList(predictionJobId = predictionJobId, partNumber = partNumber))
}

#' CreateBatchPredictionsFromExisting
#'
#' Create a new a Batch Prediction job based on an existing Batch Prediction job.
#'
#' Copies an existing job and submits it to the queue.
#'
#' @seealso The method BatchPredictionsFromExistingCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
CreateBatchPredictionsFromExisting <- function(predictionJobId, partNumber = 0, ...) {
  batchPredictionJobId <- datarobot.apicore::BatchPredictionJobId$new(predictionJobId = predictionJobId, partNumber = partNumber, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsFromExistingCreate(batchPredictionJobId = batchPredictionJobId))
}

#' CreateBatchPredictionsFromJobDefinition
#'
#' Launch a Batch Prediction job for scoring
#'
#' Launches a one-time batch prediction job based off of the previously supplied definition referring to the job definition ID and puts it on the queue.
#'
#' @seealso The method BatchPredictionsFromJobDefinitionCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
CreateBatchPredictionsFromJobDefinition <- function(jobDefinitionId, ...) {
  batchPredictionJobDefinitionId <- datarobot.apicore::BatchPredictionJobDefinitionId$new(jobDefinitionId = jobDefinitionId, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsFromJobDefinitionCreate(batchPredictionJobDefinitionId = batchPredictionJobDefinitionId))
}

#' ListBatchPredictions
#'
#' List batch prediction jobs
#'
#' Get a collection of batch prediction jobs by statuses
#'
#' @seealso The method BatchPredictionsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListBatchPredictions <- function(outputType, orderBy, source, endDateTime, jobId, hostname, startDateTime, deploymentId, cutoffHours, batchPredictionJobDefinitionId, intakeType, status, offset = 0, allJobs = FALSE, limit = 100, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsList(offset = offset, outputType = outputType, orderBy = orderBy, allJobs = allJobs, source = source, endDateTime = endDateTime, jobId = jobId, hostname = hostname, startDateTime = startDateTime, deploymentId = deploymentId, limit = limit, cutoffHours = cutoffHours, batchPredictionJobDefinitionId = batchPredictionJobDefinitionId, intakeType = intakeType, status = status))
}

#' PatchBatchPredictions
#'
#' Update a Batch Prediction job
#'
#' If a job has finished execution regardless of the result, it can have parameters changed to ensure better filtering in the job list upon retrieval. Another case: updating job scoring status externally.
#'
#' @seealso The method BatchPredictionsPatch in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
PatchBatchPredictions <- function(predictionJobId, scoredRows, jobIntakeSize, hidden, skippedRows, aborted, jobOutputSize, failedRows, started, completed, logs, status, partNumber = 0, ...) {
  batchPredictionJobUpdate <- datarobot.apicore::BatchPredictionJobUpdate$new(scoredRows = scoredRows, jobIntakeSize = jobIntakeSize, hidden = hidden, skippedRows = skippedRows, aborted = aborted, jobOutputSize = jobOutputSize, failedRows = failedRows, started = started, completed = completed, logs = logs, status = status, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsPatch(predictionJobId = predictionJobId, batchPredictionJobUpdate = batchPredictionJobUpdate, partNumber = partNumber))
}

#' RetrieveBatchPredictions
#'
#' Retrieve Batch Prediction job
#'
#' Retrieve a Batch Prediction job.
#'
#' @seealso The method BatchPredictionsRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
RetrieveBatchPredictions <- function(predictionJobId, partNumber = 0, ...) {
  return(datarobot.apicore::PredictionsApi$new()$BatchPredictionsRetrieve(predictionJobId = predictionJobId, partNumber = partNumber))
}


#' UploadTransferableModel
#'
#' Import a previously exported DRX model to be served by SSE
#'
#' This route can be used on-prem to put a given DRX model into file storage so that it can be served by a Standalone Scoring Engine (SSE). Please note however that for this to work SSE needs to be configured to use the same file storage as the main Datarbot application (namely, Public API).
#'
#' @seealso The method ImportedModelsCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
UploadTransferableModel <- function(modelFile, maxWait = 600, ...) {
  dataList <- list(file = httr::upload_file(modelFile), name = basename(modelFile))
  routeString <- "importedModels/"
  # start of generated addition
  # end of generated addition
  postResponse <- DataRobotPOST(routeString, body = dataList, returnRawResponse = TRUE, timeout = maxWait)
  modelInfo <- WaitForAsyncReturn(GetRedirectFromResponse(postResponse),
    addUrl = FALSE,
    maxWait = maxWait,
    failureStatuses = "ERROR"
  )
}

#' DeleteTransferableModel
#'
#' Delete imported by from storage along with all its metadata
#'
#' Delete previously imported DRX models from storage along with all its metadata. This deletion is permanent and cannot be reverted, but the one can export the original model and import it again.
#'
#' @seealso The method ImportedModelsDelete in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
DeleteTransferableModel <- function(importId, ...) {
  model <- GetTransferableModel(importId)
  print(model)
  routeString <- UrlJoin("importedModels", importId)
  # start of generated addition
  # end of generated addition
  response <- DataRobotDELETE(routeString)
  message(paste(
    "Model", model$modelName,
    "(import Id = ", model$id, ") deleted from prediction server"
  ))
  invisible(NULL)
}

#' ListTransferableModels
#'
#' Lists imported models optionally filtering them by a string query
#'
#' Lists imported models optionally filtering them by a string query.
#'
#' @seealso The method ImportedModelsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListTransferableModels <- function(limit = NULL, offset = NULL, query = NULL, ...) {
  routeString <- "importedModels/"
  body <- list(limit = limit, offset = offset)
  # start of generated addition
  query <- get0("query", mode = "list", ifnotfound = list())
  query$query <- query
  # end of generated addition
  modelsInfo <- GetServerDataInRows(DataRobotGET(routeString, body = body, query = query))
}

#' UpdateTransferableModel
#'
#' Allows updating some of the imported DRX model metadata fields
#'
#' Update some of the imported DRX model metadata fields.
#'
#' @seealso The method ImportedModelsPatch in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
UpdateTransferableModel <- function(importId, displayName = NULL, note = NULL, ...) {
  if (!is.null(displayName) || !is.null(note)) {
    routeString <- UrlJoin("importedModels", importId)
    body <- list(displayName = displayName, note = note)
    # start of generated addition
    # end of generated addition
    DataRobotPATCH(routeString, body = body)
  }
  GetTransferableModel(importId)
}

#' PutImportedModels
#'
#' Replace an already imported DRX model with a new one
#'
#' Replace an already imported model. The model specified by `importId` will be replaced with the model binary provided and the old model will no longer be available at this location.
#'
#' @seealso The method ImportedModelsPut in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
PutImportedModels <- function(file, importId, ...) {
  singleModelFilePayload <- datarobot.apicore::SingleModelFilePayload$new(file = file, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$ImportedModelsPut(singleModelFilePayload = singleModelFilePayload, importId = importId))
}

#' GetTransferableModel
#'
#' Get imported DRX model details
#'
#' Retrieve imported model metadata.
#'
#' @seealso The method ImportedModelsRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
GetTransferableModel <- function(importId, ...) {
  routeString <- UrlJoin("importedModels", importId)
  # start of generated addition
  # end of generated addition
  modelInfo <- DataRobotGET(routeString)
}




#' DeletePredictJob
#'
#' Cancel a queued prediction job
#'
#' Cancel a queued prediction job
#'
#' @seealso The method ProjectsPredictJobsDelete in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
DeletePredictJob <- function(project, predictJobId, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictJobs", predictJobId)
  # start of generated addition
  # end of generated addition
  DataRobotDELETE(routeString)
  message(paste("Predict job", predictJobId, "deleted from project", projectId))
  invisible(NULL)
}

#' GetPredictJobs
#'
#' List all prediction jobs for a project
#'
#' List all prediction jobs for a project
#'
#' @seealso The method ProjectsPredictJobsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
GetPredictJobs <- function(project, status = NULL, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictJobs")
  query <- if (is.null(status)) NULL else list(status = status)
  # start of generated addition
  # end of generated addition
  rawPredictJobStatus <- DataRobotGET(routeString, query = query)
  predictJobStatus <- rawPredictJobStatus
  predictJobId <- rawPredictJobStatus$id
  predictJobStatus$id <- NULL
  predictJobStatus$predictJobId <- predictJobId
  return(as.dataRobotPredictJobStatus(predictJobStatus))
}

#' GetPredictJob
#'
#' Look up a particular prediction job
#'
#' Look up a particular prediction job
#'
#' @seealso The method ProjectsPredictJobsRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
GetPredictJob <- function(project, predictJobId, ...) {
  projectId <- ValidateProject(project)
  routeString <- PredictJobRoute(projectId, predictJobId)
  # start of generated addition
  # end of generated addition
  response <- DataRobotGET(routeString, followLocation = FALSE)
  as.dataRobotPredictJobStatus(response)
}

#' UploadPredictionDatasetFromDataSource
#'
#' Upload a dataset for predictions from a ``DataSource``.
#'
#' Upload a dataset for predictions from a ``DataSource``.
#'
#' @seealso The method ProjectsPredictionDatasetsDataSourceUploadsCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
UploadPredictionDatasetFromDataSource <- function(project, dataSourceId, username, password, forecastPoint = NULL, maxWait = 600, relaxKIAFeaturesCheck = NULL, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictionDatasets", "dataSourceUploads")
  body <- list(
    dataSourceId = dataSourceId,
    user = username,
    password = password
  )
  if (!is.null(forecastPoint)) {
    body$forecastPoint <- forecastPoint
  }
  if (!is.null(relaxKIAFeaturesCheck)) {
    body$relaxKIAFeaturesCheck <- relaxKIAFeaturesCheck
  }
  # start of generated addition
  # end of generated addition
  postResponse <- DataRobotPOST(routeString, body = body, returnRawResponse = TRUE, timeout = maxWait)
  asyncUrl <- GetRedirectFromResponse(postResponse)
  dataset <- PredictionDatasetFromAsyncUrl(asyncUrl, maxWait = maxWait)
  as.dataRobotPredictionDataset(dataset)
}

#' UploadPredictionDatasetFromCatalog
#'
#' Create prediction dataset
#'
#' Create a prediction dataset from a Dataset Item in the catalog.
#'
#' @seealso The method ProjectsPredictionDatasetsDatasetUploadsCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
UploadPredictionDatasetFromCatalog <- function(project, datasetId, datasetVersionId = NULL, forecastPoint = NULL, predictionsStartDate = NULL, predictionsEndDate = NULL, maxWait = 600, relaxKIAFeaturesCheck = NULL, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictionDatasets", "datasetUploads")
  body <- list(datasetId = datasetId)
  if (!is.null(datasetVersionId)) {
    body$datasetVersionId <- datasetVersionId
  }
  if (!is.null(forecastPoint) && (!is.null(predictionsStartDate) || !is.null(predictionsEndDate))) {
    stop(
      sQuote("forecastPoint"), " cannot be provided along with ", sQuote("predictionsStartDate"),
      " or ", sQuote("predictionsEndDate"), "."
    )
  }
  if (!is.null(predictionsStartDate) && is.null(predictionsEndDate)) {
    stop(
      "You must specify ", sQuote("predictionsEndDate"), " if you also specify ",
      sQuote("predictionsStartDate"), "."
    )
  }
  if (!is.null(predictionsEndDate) && is.null(predictionsStartDate)) {
    stop(
      "You must specify ", sQuote("predictionsStartDate"), " if you also specify ",
      sQuote("predictionsEndDate"), "."
    )
  }
  if (!is.null(forecastPoint)) {
    body$forecastPoint <- forecastPoint
  }
  if (!is.null(predictionsStartDate)) {
    body$predictionsStartDate <- predictionsStartDate
  }
  if (!is.null(predictionsEndDate)) {
    body$predictionsEndDate <- predictionsEndDate
  }
  if (!is.null(relaxKIAFeaturesCheck)) {
    body$relaxKIAFeaturesCheck <- relaxKIAFeaturesCheck
  }
  # start of generated addition
  # end of generated addition
  postResponse <- DataRobotPOST(routeString, body = body, returnRawResponse = TRUE, timeout = maxWait)
  asyncUrl <- GetRedirectFromResponse(postResponse)
  dataset <- PredictionDatasetFromAsyncUrl(asyncUrl, maxWait = maxWait)
  as.dataRobotPredictionDataset(dataset)
}

#' DeletePredictionDataset
#'
#' Delete a dataset that was uploaded for prediction.
#'
#' Delete a dataset that was uploaded for prediction.
#'
#' @seealso The method ProjectsPredictionDatasetsDelete in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
DeletePredictionDataset <- function(project, datasetId, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictionDatasets", datasetId)
  # start of generated addition
  # end of generated addition
  DataRobotDELETE(routeString)
  invisible(NULL)
}

#' CreateProjectsPredictionDatasetsFileUploads
#'
#' Upload a file for predictions from an attached file.
#'
#' Upload a file for predictions from an attached file.
#'
#' @seealso The method ProjectsPredictionDatasetsFileUploadsCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
CreateProjectsPredictionDatasetsFileUploads <- function(predictionsEndDate, file, credentials, relaxKnownInAdvanceFeaturesCheck, predictionsStartDate, actualValueColumn, secondaryDatasetsConfigId, forecastPoint, projectId, ...) {
  predictionFileUpload <- datarobot.apicore::PredictionFileUpload$new(predictionsEndDate = predictionsEndDate, file = file, credentials = credentials, relaxKnownInAdvanceFeaturesCheck = relaxKnownInAdvanceFeaturesCheck, predictionsStartDate = predictionsStartDate, actualValueColumn = actualValueColumn, secondaryDatasetsConfigId = secondaryDatasetsConfigId, forecastPoint = forecastPoint, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$ProjectsPredictionDatasetsFileUploadsCreate(predictionFileUpload = predictionFileUpload, projectId = projectId))
}

#' ListPredictionDatasets
#'
#' List predictions datasets uploaded to a project.
#'
#' List predictions datasets uploaded to a project.
#'
#' @seealso The method ProjectsPredictionDatasetsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListPredictionDatasets <- function(project, offset = 0, limit = 0, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictionDatasets")
  # start of generated addition
  query <- get0("query", mode = "list", ifnotfound = list())
  query$offset <- offset
  query$limit <- limit
  # end of generated addition
  datasetInfo <- DataRobotGET(routeString, simplifyDataFrame = FALSE, query = query)
  datasetInfo <- GetServerDataInRows(datasetInfo)
  as.listOfDataRobotPredictionDatasets(datasetInfo)
}

#' GetPredictionDataset
#'
#' Get the metadata of a specific dataset. This only works for datasets uploaded to an existing project for prediction.
#'
#' Get the metadata of a specific dataset. This only works for datasets uploaded to an existing project for prediction.
#'
#' @seealso The method ProjectsPredictionDatasetsRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
GetPredictionDataset <- function(project, datasetId, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictionDatasets", datasetId)
  # start of generated addition
  # end of generated addition
  response <- DataRobotGET(routeString)
  as.dataRobotPredictionDataset(response)
}

#' UploadPredictionDataset
#'
#' Upload a file for predictions from a URL.
#'
#' Upload a file for predictions from a URL.
#'
#' @seealso The method ProjectsPredictionDatasetsUrlUploadsCreate in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
UploadPredictionDataset <- function(project, dataSource, forecastPoint = NULL, predictionsStartDate = NULL, predictionsEndDate = NULL, relaxKIAFeaturesCheck = NULL, maxWait = 600, ...) {
  projectId <- ValidateProject(project)
  if (isURL(dataSource)) {
    routeString <- UrlJoin("projects", projectId, "predictionDatasets", "urlUploads")
    dataList <- list(url = dataSource)
  } else {
    dataPath <- DataPathFromDataArg(dataSource)
    routeString <- UrlJoin("projects", projectId, "predictionDatasets", "fileUploads")
    dataList <- list(file = httr::upload_file(dataPath))
  }
  if (!is.null(forecastPoint) && (!is.null(predictionsStartDate) || !is.null(predictionsEndDate))) {
    stop(
      sQuote("forecastPoint"), " cannot be provided along with ", sQuote("predictionsStartDate"),
      " or ", sQuote("predictionsEndDate"), "."
    )
  }
  if (!is.null(predictionsStartDate) && is.null(predictionsEndDate)) {
    stop(
      "You must specify ", sQuote("predictionsEndDate"), " if you also specify ",
      sQuote("predictionsStartDate"), "."
    )
  }
  if (!is.null(predictionsEndDate) && is.null(predictionsStartDate)) {
    stop(
      "You must specify ", sQuote("predictionsStartDate"), " if you also specify ",
      sQuote("predictionsEndDate"), "."
    )
  }
  if (!is.null(forecastPoint)) {
    dataList$forecastPoint <- forecastPoint
  }
  if (!is.null(predictionsStartDate)) {
    dataList$predictionsStartDate <- predictionsStartDate
  }
  if (!is.null(predictionsEndDate)) {
    dataList$predictionsEndDate <- predictionsEndDate
  }
  if (!is.null(relaxKIAFeaturesCheck)) {
    dataList$relaxKIAFeaturesCheck <- relaxKIAFeaturesCheck
  }
  # start of generated addition
  # end of generated addition
  postResponse <- DataRobotPOST(routeString, body = dataList, returnRawResponse = TRUE, timeout = maxWait)
  asyncUrl <- GetRedirectFromResponse(postResponse)
  dataset <- PredictionDatasetFromAsyncUrl(asyncUrl, maxWait = maxWait)
  as.dataRobotPredictionDataset(dataset)
}


#' GetPredictionExplanationsPage
#'
#' Retrieve stored Prediction Explanations.
#'
#' Retrieve stored Prediction Explanations. Each PredictionExplanationsRow retrieved corresponds to a row of the prediction dataset, although some rows may not have had prediction explanations computed depending on the thresholds selected.
#'
#' @seealso The method ProjectsPredictionExplanationsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
GetPredictionExplanationsPage <- function(project, predictionExplanationId, limit = NULL, offset = 0, excludeAdjustedPredictions = TRUE, adjustmentMethod = NULL, count = NULL, data = NULL, id = NULL, next_ = NULL, predictionExplanationsRecordLocation = NULL, previous = NULL, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin(
    "projects", projectId, "predictionExplanations",
    predictionExplanationId
  )
  excludeAdjustedPredictions <- tolower(as.character(identical(excludeAdjustedPredictions, TRUE)))
  params <- list(
    offset = offset,
    limit = limit,
    excludeAdjustedPredictions = excludeAdjustedPredictions
  )
  # start of generated addition
  body <- get0("body", mode = "list", ifnotfound = list())
  body$predictionExplanationsRetrieve <- get0("body$predictionExplanationsRetrieve", mode = "list", ifnotfound = list())

  body$predictionExplanationsRetrieve$adjustmentMethod <- adjustmentMethod

  body$predictionExplanationsRetrieve$count <- count

  body$predictionExplanationsRetrieve$data <- data

  body$predictionExplanationsRetrieve$id <- id

  body$predictionExplanationsRetrieve$next_ <- next_

  body$predictionExplanationsRetrieve$predictionExplanationsRecordLocation <- predictionExplanationsRecordLocation

  body$predictionExplanationsRetrieve$previous <- previous
  # end of generated addition
  CleanServerData(DataRobotGET(routeString, simplifyDataFrame = FALSE, query = params, body = body))
}

#' DeletePredictionExplanations
#'
#' Delete saved Prediction Explanations.
#'
#' Delete saved Prediction Explanations. Deletes both the actual prediction explanations and the corresponding PredictionExplanationsRecord.
#'
#' @seealso The method ProjectsPredictionExplanationsRecordsDelete in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
DeletePredictionExplanations <- function(project, predictionExplanationId, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin(
    "projects", projectId, "predictionExplanationsRecords",
    predictionExplanationId
  )
  # start of generated addition
  # end of generated addition
  DataRobotDELETE(routeString)
  message(paste(
    "Prediction explanations ", predictionExplanationId,
    "deleted from project", projectId
  ))
  invisible(TRUE)
}

#' ListPredictionExplanationsMetadata
#'
#' List PredictionExplanationsRecord objects for a project.
#'
#' List PredictionExplanationsRecord objects for a project. These contain metadata about the computed prediction explanations and the location at which the PredictionExplanations can be retrieved.
#'
#' @seealso The method ProjectsPredictionExplanationsRecordsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListPredictionExplanationsMetadata <- function(project, modelId = NULL, limit = NULL, offset = NULL, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictionExplanationsRecords")
  body <- list(modelId = modelId, limit = limit, offset = offset)
  # start of generated addition
  # end of generated addition
  response <- DataRobotGET(routeString, simplifyDataFrame = FALSE, body = body)
  return(GetServerDataInRows(response))
}

#' GetPredictionExplanationsMetadata
#'
#' Retrieve a PredictionExplanationsRecord object.
#'
#' Retrieve a PredictionExplanationsRecord object. A PredictionExplanationsRecord contains metadata about the computed prediction explanations and the location at which the PredictionExplanations can be retrieved.
#'
#' @seealso The method ProjectsPredictionExplanationsRecordsRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
GetPredictionExplanationsMetadata <- function(project, predictionExplanationId, datasetId = NULL, finishTime = NULL, id = NULL, maxExplanations = NULL, modelId = NULL, numColumns = NULL, predictionExplanationsLocation = NULL, predictionThreshold = NULL, thresholdHigh = NULL, thresholdLow = NULL, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin(
    "projects", projectId, "predictionExplanationsRecords",
    predictionExplanationId
  )
  # start of generated addition
  body <- get0("body", mode = "list", ifnotfound = list())
  body$predictionExplanationsRecord <- get0("body$predictionExplanationsRecord", mode = "list", ifnotfound = list())

  body$predictionExplanationsRecord$datasetId <- datasetId

  body$predictionExplanationsRecord$finishTime <- finishTime

  body$predictionExplanationsRecord$id <- id

  body$predictionExplanationsRecord$maxExplanations <- maxExplanations

  body$predictionExplanationsRecord$modelId <- modelId

  body$predictionExplanationsRecord$numColumns <- numColumns

  body$predictionExplanationsRecord$predictionExplanationsLocation <- predictionExplanationsLocation

  body$predictionExplanationsRecord$predictionThreshold <- predictionThreshold

  body$predictionExplanationsRecord$thresholdHigh <- thresholdHigh

  body$predictionExplanationsRecord$thresholdLow <- thresholdLow
  # end of generated addition
  return(DataRobotGET(routeString, simplifyDataFrame = FALSE, body = body))
}


#' ListPredictions
#'
#' Get a list of prediction records.
#'
#' Get a list of prediction records.  .. deprecated:: v2.21     Use :http:get:`/api/v2/projects/(projectId)/predictionsMetadata/` instead. The only     difference is that parameter `datasetId` is renamed to `predictionDatasetId`     both in request and response.
#'
#' @seealso The method ProjectsPredictionsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListPredictions <- function(project, modelId = NULL, datasetId = NULL, offset = 0, limit = 1000, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "predictions")
  query <- list()
  query$modelId <- modelId
  query$datasetId <- datasetId
  # start of generated addition
  query <- get0("query", mode = "list", ifnotfound = list())
  query$offset <- offset
  query$limit <- limit
  # end of generated addition
  response <- DataRobotGET(routeString, query = query)
  response <- GetServerDataInRows(response)
  as.dataRobotPredictionsList(response)
}

#' ListProjectsPredictionsMetadata
#'
#' Get a list of prediction metadata records.
#'
#' Use the ID of a metadata object to get the complete set of predictions.
#'
#' @seealso The method ProjectsPredictionsMetadataList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListProjectsPredictionsMetadata <- function(predictionDatasetId, modelId, projectId, offset = 0, limit = 1000, ...) {
  return(datarobot.apicore::PredictionsApi$new()$ProjectsPredictionsMetadataList(predictionDatasetId = predictionDatasetId, offset = offset, modelId = modelId, limit = limit, projectId = projectId))
}

#' RetrieveProjectsPredictionsMetadata
#'
#' Retrieve metadata for a set of predictions.
#'
#' Use the ID of a metadata object to get the complete set of predictions.
#'
#' @seealso The method ProjectsPredictionsMetadataRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
RetrieveProjectsPredictionsMetadata <- function(projectId, predictionId, ...) {
  return(datarobot.apicore::PredictionsApi$new()$ProjectsPredictionsMetadataRetrieve(projectId = projectId, predictionId = predictionId))
}

#' RetrieveProjectsPredictions
#'
#' Get a completed set of predictions.
#'
#' Retrieve predictions that have previously been computed. Training predictions encoded either as JSON or CSV. If CSV output was requested, the returned CSV data will contain the following columns:  * For regression projects: `row_id` and `prediction`. * For binary classification projects: `row_id`, `prediction`,   `class_<positive_class_label>` and `class_<negative_class_label>`. * For multiclass projects: `row_id`, `prediction` and a   `class_<class_label>` for each class. * For multilabel projects: `row_id` and for each class   `prediction_<class_label>` and `class_<class_label>`. * For time-series, these additional columns will be added: `forecast_point`,   `forecast_distance`, `timestamp`, and `series_id`.  .. minversion:: v2.21      * If `explanationAlgorithm` = 'shap', these additional columns will be added:       triplets of (`Explanation_<i>_feature_name`,       `Explanation_<i>_feature_value`, and `Explanation_<i>_strength`) for `i` ranging       from 1 to `maxExplanations`, `shap_remaining_total` and `shap_base_value`. Binary       classification projects will also have `explained_class`, the class for which       positive SHAP values imply an increased probability.
#'
#' @seealso The method ProjectsPredictionsRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
RetrieveProjectsPredictions <- function(shapMulticlassLevel, projectId, predictionId, accept, ...) {
  return(datarobot.apicore::PredictionsApi$new()$ProjectsPredictionsRetrieve(shapMulticlassLevel = shapMulticlassLevel, projectId = projectId, predictionId = predictionId, accept = accept))
}


#' DeleteScheduledJobs
#'
#' Delete scheduled job
#'
#' Delete scheduled job
#'
#' @seealso The method ScheduledJobsDelete in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
DeleteScheduledJobs <- function(jobId, ...) {
  return(datarobot.apicore::PredictionsApi$new()$ScheduledJobsDelete(jobId = jobId))
}

#' ListScheduledJobs
#'
#' List scheduled deployment batch prediction jobs a user can view
#'
#' Get a list of scheduled batch prediction jobs a user can view
#'
#' @seealso The method ScheduledJobsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListScheduledJobs <- function(integrationTypeName, deploymentId, filterEnabled, search = "", offset = 0, queryByUser = "createdBy", limit = 20, orderBy = "name", typeId = "predictionIntegration", ...) {
  return(datarobot.apicore::PredictionsApi$new()$ScheduledJobsList(integrationTypeName = integrationTypeName, search = search, offset = offset, queryByUser = queryByUser, deploymentId = deploymentId, limit = limit, orderBy = orderBy, typeId = typeId, filterEnabled = filterEnabled))
}

#' PatchScheduledJobs
#'
#' Run or stop a previously created scheduled integration job
#'
#' Run or stop a previously created scheduled integration job
#'
#' @seealso The method ScheduledJobsPatch in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
PatchScheduledJobs <- function(jobId, status, ...) {
  scheduledJobRunStop <- datarobot.apicore::ScheduledJobRunStop$new(status = status, validateParams = TRUE)
  return(datarobot.apicore::PredictionsApi$new()$ScheduledJobsPatch(jobId = jobId, scheduledJobRunStop = scheduledJobRunStop))
}

#' RetrieveScheduledJobs
#'
#' List a single deployment batch prediction job
#'
#' Get a scheduled batch prediction job
#'
#' @seealso The method ScheduledJobsRetrieve in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
RetrieveScheduledJobs <- function(jobId, ...) {
  return(datarobot.apicore::PredictionsApi$new()$ScheduledJobsRetrieve(jobId = jobId))
}

#' ListTrainingPredictions
#'
#' List training prediction jobs
#'
#' Get a list of training prediction records
#'
#' @seealso The method TrainingPredictionsList in [datarobot.apicore::PredictionsApi], which this function wraps.
#' @family Predictions
#' @export
ListTrainingPredictions <- function(project, offset = 0, limit = 0, ...) {
  projectId <- ValidateProject(project)
  routeString <- UrlJoin("projects", projectId, "trainingPredictions")
  # start of generated addition
  query <- get0("query", mode = "list", ifnotfound = list())
  query$offset <- offset
  query$limit <- limit
  # end of generated addition
  serverData <- DataRobotGET(routeString, simplifyDataFrame = FALSE, query = query)
  rows <- GetServerDataInRows(serverData)
  as.dataRobotTrainingPredictionList(rows)
}
